"""
LLM ì „ìš© ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
ê·œì¹™ ê¸°ë°˜ ë¡œì§ì„ ì œê±°í•˜ê³  LLMë§Œ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬
ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
ë©€í‹°ëª¨ë‹¬ (ì´ë¯¸ì§€+JSON) ë¶„ì„ ì§€ì›
"""

import json
import asyncio
import base64
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from copy import deepcopy


def encode_image_to_base64(image_path: str) -> Optional[str]:
    """ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©"""
    try:
        path = Path(image_path)
        if not path.exists():
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return None
        
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        return None


def get_image_mime_type(image_path: str) -> str:
    """ì´ë¯¸ì§€ MIME íƒ€ì… ë°˜í™˜"""
    path = Path(image_path).suffix.lower()
    mime_types = {
        '.png': 'image/png',
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.gif': 'image/gif',
        '.webp': 'image/webp'
    }
    return mime_types.get(path, 'image/png')
from json_utils import (
    prepare_llm_context, 
    find_node_by_id, 
    extract_subtree,
    load_json_partial
)
from prompt_loader import PromptLoader


class LLMRuleAnalyzerAgent:
    """
    Agent 1: LLM ê¸°ë°˜ Rule Analyzer
    - LLMì„ ì‚¬ìš©í•˜ì—¬ ê° ë…¸ë“œì— ì ìš©í•  resizing ê·œì¹™ì„ ê²°ì •
    - ê·œì¹™ íŒŒì¼ ëŒ€ì‹  LLMì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê²°ì •
    """
    
    def __init__(self, llm_client, prompt_loader: Optional[PromptLoader] = None):
        """
        Args:
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸ (OpenAI, Anthropic ë“±)
            prompt_loader: í”„ë¡¬í”„íŠ¸ ë¡œë” (Noneì´ë©´ ìë™ ìƒì„±)
        """
        self.llm_client = llm_client
        self.prompt_loader = prompt_loader or PromptLoader()
    
    def determine_resizing(self, node: Dict, parent: Optional[Dict] = None,
                          siblings: List[Dict] = None, 
                          context_nodes: List[Dict] = None,
                          is_root: bool = False) -> Dict:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œì˜ resizing ê·œì¹™ ê²°ì •
        
        Args:
            node: í˜„ì¬ ë…¸ë“œ
            parent: ë¶€ëª¨ ë…¸ë“œ
            siblings: í˜•ì œ ë…¸ë“œë“¤
            context_nodes: ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ë…¸ë“œë“¤
            is_root: ìµœìƒìœ„ ë¸”ë¡ ì—¬ë¶€
        
        Returns:
            resizing ì†ì„±ì´ ì¶”ê°€ëœ ë…¸ë“œ
        """
        if not self.llm_client:
            # LLM ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            node['resizing'] = 'fill * fill'
            return node
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_resizing_prompt(node, parent, siblings, context_nodes, is_root)
        
        # LLM í˜¸ì¶œ
        response = self._call_llm(prompt)
        
        # ì‘ë‹µ íŒŒì‹± ë° ì ìš©
        resizing = self._parse_resizing_response(response)
        node['resizing'] = resizing
        
        return node
    
    def _create_resizing_prompt(self, node: Dict, parent: Optional[Dict],
                               siblings: List[Dict], context_nodes: List[Dict],
                               is_root: bool) -> str:
        """
        Resizing ê·œì¹™ ê²°ì •ì„ ìœ„í•œ ìƒì„¸í•œ LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë§¤ìš° êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±ë˜ì–´ LLMì´ ì •í™•í•œ íŒë‹¨ì„ í•  ìˆ˜ ìˆë„ë¡ í•¨
        """
        
        # ë…¸ë“œ ì •ë³´ ìˆ˜ì§‘
        node_info = {
            'id': node.get('id'),
            'role': node.get('role', ''),
            'type': node.get('type', ''),
            'content': node.get('content', ''),
            'has_children': len(node.get('children', [])) > 0,
            'children_count': len(node.get('children', [])),
            'children_types': [c.get('type') for c in node.get('children', [])[:5]]
        }
        
        # ë¶€ëª¨ ì •ë³´
        parent_info = None
        if parent:
            parent_info = {
                'role': parent.get('role', ''),
                'type': parent.get('type', ''),
                'direction': parent.get('direction'),
                'resizing': parent.get('resizing', '')
            }
        
        # í˜•ì œ ì •ë³´
        siblings_info = []
        if siblings:
            siblings_info = [
                {
                    'id': s.get('id'),
                    'role': s.get('role', ''),
                    'type': s.get('type', ''),
                    'position': 'right'  # ì˜¤ë¥¸ìª½ í˜•ì œ
                }
                for s in siblings[:3]
            ]
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        context_summary = {
            'total_nodes': len(context_nodes),
            'sample_nodes': context_nodes[:5] if context_nodes else []
        }
        
        # YAML í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        context = {
            'node_info': node_info,
            'parent_info': parent_info,
            'siblings_info': siblings_info,
            'context_summary': context_summary
        }
        prompt = self.prompt_loader.get_prompt('resizing', context)
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        config = self.prompt_loader.get_llm_config('resizing')
        
        if hasattr(self.llm_client, 'chat'):
            # OpenAI ìŠ¤íƒ€ì¼
            system_message = self.prompt_loader._prompts['resizing'].get('system_role', '')
            response = self.llm_client.chat.completions.create(
                model=config.get('model', 'gpt-4'),
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ],
                temperature=config.get('temperature', 0.2),
                max_tokens=config.get('max_tokens', 200)
            )
            return response.choices[0].message.content
        elif hasattr(self.llm_client, 'complete'):
            return self.llm_client.complete(prompt)
        else:
            return '{"resizing": "fill * fill", "reason": "ê¸°ë³¸ê°’"}'
    
    def _parse_resizing_response(self, response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ resizing ê°’ ì¶”ì¶œ"""
        try:
            # JSON ì¶”ì¶œ
            if '```json' in response:
                json_start = response.find('```json') + 7
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            elif '```' in response:
                json_start = response.find('```') + 3
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            else:
                # JSONì´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆì„ ìˆ˜ë„ ìˆìŒ
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
            
            result = json.loads(json_str)
            resizing = result.get('resizing', 'fill * fill')
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if '*' not in resizing:
                return 'fill * fill'  # ê¸°ë³¸ê°’
            
            return resizing
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            print(f"âš ï¸ Resizing íŒŒì‹± ì˜¤ë¥˜: {e}")
            return 'fill * fill'  # ê¸°ë³¸ê°’


class LLMLayoutAnalyzerAgent:
    """
    Agent 2: LLM ê¸°ë°˜ Layout Analyzer
    - LLMì„ ì‚¬ìš©í•˜ì—¬ direction, gap, padding ê²°ì •
    - ë…¸ë“œì˜ êµ¬ì¡°ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë ˆì´ì•„ì›ƒ ì†ì„± ì„¤ì •
    """
    
    def __init__(self, llm_client, prompt_loader: Optional[PromptLoader] = None):
        self.llm_client = llm_client
        self.prompt_loader = prompt_loader or PromptLoader()
    
    def analyze_and_enrich(self, node: Dict, parent: Optional[Dict] = None) -> Dict:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë ˆì´ì•„ì›ƒ ì†ì„± ë¶„ì„ ë° ì¶”ê°€
        
        Args:
            node: í˜„ì¬ ë…¸ë“œ
            parent: ë¶€ëª¨ ë…¸ë“œ
        
        Returns:
            ë ˆì´ì•„ì›ƒ ì†ì„±ì´ ì¶”ê°€ëœ ë…¸ë“œ
        """
        if not self.llm_client:
            # LLM ì—†ìœ¼ë©´ ê¸°ë³¸ ë¡œì§
            return self._apply_default_layout(node)
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_layout_prompt(node, parent)
        
        # LLM í˜¸ì¶œ
        response = self._call_llm(prompt)
        
        # ì‘ë‹µ íŒŒì‹± ë° ì ìš©
        layout_props = self._parse_layout_response(response)
        self._apply_layout_properties(node, layout_props)
        
        return node
    
    def _create_layout_prompt(self, node: Dict, parent: Optional[Dict]) -> str:
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ì„ ìœ„í•œ ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        node_info = {
            'id': node.get('id'),
            'role': node.get('role', ''),
            'type': node.get('type', ''),
            'has_children': len(node.get('children', [])) > 0,
            'children_count': len(node.get('children', [])),
            'children_types': [c.get('type') for c in node.get('children', [])[:5]],
            'existing_gap': node.get('gap'),
            'existing_direction': node.get('direction'),
            'existing_padding': node.get('padding')
        }
        
        parent_info = None
        if parent:
            parent_info = {
                'role': parent.get('role', ''),
                'type': parent.get('type', ''),
                'direction': parent.get('direction', '')
            }
        
        # YAML í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        context = {
            'node_info': node_info,
            'parent_info': parent_info
        }
        prompt = self.prompt_loader.get_prompt('layout', context)
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        config = self.prompt_loader.get_llm_config('layout')
        
        if hasattr(self.llm_client, 'chat'):
            system_message = self.prompt_loader._prompts['layout'].get('system_role', '')
            response = self.llm_client.chat.completions.create(
                model=config.get('model', 'gpt-4'),
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ],
                temperature=config.get('temperature', 0.2),
                max_tokens=config.get('max_tokens', 300)
            )
            return response.choices[0].message.content
        elif hasattr(self.llm_client, 'complete'):
            return self.llm_client.complete(prompt)
        else:
            return '{"direction": "vertical", "gap": 10, "padding": {"top":0,"right":0,"bottom":0,"left":0}}'
    
    def _parse_layout_response(self, response: str) -> Dict:
        """LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            if '```json' in response:
                json_start = response.find('```json') + 7
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            elif '```' in response:
                json_start = response.find('```') + 3
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
            
            result = json.loads(json_str)
            return result
        except (json.JSONDecodeError, ValueError) as e:
            print(f"âš ï¸ Layout íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._get_default_layout()
    
    def _apply_layout_properties(self, node: Dict, layout_props: Dict):
        """ë ˆì´ì•„ì›ƒ ì†ì„± ì ìš©"""
        if 'direction' in layout_props:
            node['direction'] = layout_props['direction']
        
        if 'gap' in layout_props and layout_props['gap'] is not None:
            if 'gap' not in node:  # ê¸°ì¡´ ê°’ì´ ì—†ì„ ë•Œë§Œ
                node['gap'] = layout_props['gap']
        
        if 'horizontalGap' in layout_props and layout_props['horizontalGap'] is not None:
            node['horizontalGap'] = layout_props['horizontalGap']
        
        if 'verticalGap' in layout_props and layout_props['verticalGap'] is not None:
            node['verticalGap'] = layout_props['verticalGap']
        
        if 'padding' in layout_props:
            if 'padding' not in node:  # ê¸°ì¡´ ê°’ì´ ì—†ì„ ë•Œë§Œ
                node['padding'] = layout_props['padding']
    
    def _apply_default_layout(self, node: Dict) -> Dict:
        """ê¸°ë³¸ ë ˆì´ì•„ì›ƒ ì ìš© (LLM ì—†ì„ ë•Œ)"""
        node_type = node.get('type', '')
        if node_type == 'HStack':
            node['direction'] = 'horizontal'
        elif node_type == 'VStack':
            node['direction'] = 'vertical'
        elif node_type == 'Group':
            node['direction'] = 'vertical'
        
        if 'children' in node and len(node.get('children', [])) > 1:
            if 'gap' not in node:
                node['gap'] = 10
            if node.get('direction') == 'horizontal':
                node['horizontalGap'] = node.get('gap', 10)
            elif node.get('direction') == 'vertical':
                node['verticalGap'] = node.get('gap', 10)
        
        if 'padding' not in node:
            node['padding'] = {'top': 0, 'right': 0, 'bottom': 0, 'left': 0}
        
        return node
    
    def _get_default_layout(self) -> Dict:
        """ê¸°ë³¸ ë ˆì´ì•„ì›ƒ ê°’"""
        return {
            'direction': 'vertical',
            'gap': 10,
            'padding': {'top': 0, 'right': 0, 'bottom': 0, 'left': 0}
        }


class LLMAlignmentEnricherAgent:
    """
    Agent 3: LLM ê¸°ë°˜ Alignment Enricher
    - LLMì„ ì‚¬ìš©í•˜ì—¬ alignment ì†ì„± ê²°ì •
    - ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìµœì ì˜ ì •ë ¬ ë°©ì‹ ì„¤ì •
    """
    
    def __init__(self, llm_client, prompt_loader: Optional[PromptLoader] = None):
        self.llm_client = llm_client
        self.prompt_loader = prompt_loader or PromptLoader()
    
    def enrich_alignments(self, node: Dict, parent: Optional[Dict] = None) -> Dict:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ alignment ì†ì„± ì¶”ê°€
        
        Args:
            node: í˜„ì¬ ë…¸ë“œ
            parent: ë¶€ëª¨ ë…¸ë“œ
        
        Returns:
            alignment ì†ì„±ì´ ì¶”ê°€ëœ ë…¸ë“œ
        """
        if not self.llm_client:
            return self._apply_default_alignment(node)
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_alignment_prompt(node, parent)
        
        # LLM í˜¸ì¶œ
        response = self._call_llm(prompt)
        
        # ì‘ë‹µ íŒŒì‹± ë° ì ìš©
        alignment_props = self._parse_alignment_response(response)
        self._apply_alignment_properties(node, alignment_props)
        
        return node
    
    def _create_alignment_prompt(self, node: Dict, parent: Optional[Dict]) -> str:
        """Alignment ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        node_info = {
            'id': node.get('id'),
            'role': node.get('role', ''),
            'type': node.get('type', ''),
            'content': node.get('content', ''),
            'existing_alignment': node.get('alignment'),
            'direction': node.get('direction'),
            'has_children': len(node.get('children', [])) > 0
        }
        
        parent_info = None
        if parent:
            parent_info = {
                'role': parent.get('role', ''),
                'direction': parent.get('direction', ''),
                'alignment': parent.get('alignment', '')
            }
        
        # YAML í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        context = {
            'node_info': node_info,
            'parent_info': parent_info
        }
        prompt = self.prompt_loader.get_prompt('alignment', context)
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        config = self.prompt_loader.get_llm_config('alignment')
        
        if hasattr(self.llm_client, 'chat'):
            system_message = self.prompt_loader._prompts['alignment'].get('system_role', '')
            response = self.llm_client.chat.completions.create(
                model=config.get('model', 'gpt-4'),
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ],
                temperature=config.get('temperature', 0.2),
                max_tokens=config.get('max_tokens', 200)
            )
            return response.choices[0].message.content
        elif hasattr(self.llm_client, 'complete'):
            return self.llm_client.complete(prompt)
        else:
            return '{"alignment": "center", "verticalAlignment": "center", "horizontalAlignment": "center"}'
    
    def _parse_alignment_response(self, response: str) -> Dict:
        """LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            if '```json' in response:
                json_start = response.find('```json') + 7
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            elif '```' in response:
                json_start = response.find('```') + 3
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
            
            result = json.loads(json_str)
            return result
        except (json.JSONDecodeError, ValueError) as e:
            print(f"âš ï¸ Alignment íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._get_default_alignment()
    
    def _apply_alignment_properties(self, node: Dict, alignment_props: Dict):
        """Alignment ì†ì„± ì ìš©"""
        if 'alignment' in alignment_props:
            node['alignment'] = alignment_props['alignment']
        if 'verticalAlignment' in alignment_props:
            node['verticalAlignment'] = alignment_props['verticalAlignment']
        if 'horizontalAlignment' in alignment_props:
            node['horizontalAlignment'] = alignment_props['horizontalAlignment']
    
    def _apply_default_alignment(self, node: Dict) -> Dict:
        """ê¸°ë³¸ alignment ì ìš©"""
        existing = node.get('alignment')
        if existing == 'center':
            node['alignment'] = 'center'
            node['verticalAlignment'] = 'center'
            node['horizontalAlignment'] = 'center'
        elif existing == 'leading':
            node['alignment'] = 'leading'
            node['horizontalAlignment'] = 'left'
            node['verticalAlignment'] = 'center'
        elif existing == 'trailing':
            node['alignment'] = 'trailing'
            node['horizontalAlignment'] = 'right'
            node['verticalAlignment'] = 'center'
        else:
            node['alignment'] = 'center'
            node['verticalAlignment'] = 'center'
            node['horizontalAlignment'] = 'center'
        return node
    
    def _get_default_alignment(self) -> Dict:
        """ê¸°ë³¸ alignment ê°’"""
        return {
            'alignment': 'center',
            'verticalAlignment': 'center',
            'horizontalAlignment': 'center'
        }


class LLMRoleValidatorAgent:
    """
    Agent 4: LLM ê¸°ë°˜ Role Validator (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
    - LLMì„ ì‚¬ìš©í•˜ì—¬ ê° ë…¸ë“œì˜ Roleì´ ì˜¬ë°”ë¥´ê²Œ í• ë‹¹ë˜ì—ˆëŠ”ì§€ ê²€ì¦
    - ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ì‹œê°ì  ì˜ë¯¸ íŒŒì•…
    - ê³„ì¸µ êµ¬ì¡°, ì œì•½ ì¡°ê±´, ì˜ë¯¸ë¡ ì  ì¼ê´€ì„± ê²€ì‚¬
    - ë¬¸ì œ ë°œê²¬ ì‹œ ìë™ ìˆ˜ì • (Role ë³€ê²½, Groupìœ¼ë¡œ ë¬¶ê¸° ë“±)
    """
    
    def __init__(self, llm_client, prompt_loader: Optional[PromptLoader] = None,
                 reference_image_path: Optional[str] = None):
        """
        Args:
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸ (OpenAI, Anthropic ë“±)
            prompt_loader: í”„ë¡¬í”„íŠ¸ ë¡œë” (Noneì´ë©´ ìë™ ìƒì„±)
            reference_image_path: ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ (ë©€í‹°ëª¨ë‹¬ ë¶„ì„ìš©)
        """
        self.llm_client = llm_client
        self.prompt_loader = prompt_loader or PromptLoader()
        self.pending_structure_changes = []  # êµ¬ì¡° ë³€ê²½ ëŒ€ê¸°ì—´
        
        # ë©€í‹°ëª¨ë‹¬ ì„¤ì •
        self.reference_image_path = reference_image_path
        self.reference_image_base64 = None
        if reference_image_path:
            self.reference_image_base64 = encode_image_to_base64(reference_image_path)
            if self.reference_image_base64:
                print(f"ğŸ“· ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {reference_image_path}")
    
    def validate_role(self, node: Dict, parent: Optional[Dict] = None,
                     siblings: List[Dict] = None,
                     children: List[Dict] = None) -> Dict:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œì˜ Role ê²€ì¦
        
        Args:
            node: í˜„ì¬ ë…¸ë“œ
            parent: ë¶€ëª¨ ë…¸ë“œ
            siblings: í˜•ì œ ë…¸ë“œë“¤
            children: ìì‹ ë…¸ë“œë“¤
        
        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.llm_client:
            # LLM ì—†ìœ¼ë©´ ê¸°ë³¸ ê²€ì¦ ê²°ê³¼
            return {
                'is_valid': True,
                'current_role': node.get('role', ''),
                'issues': [],
                'suggestions': [],
                'confidence': 0.5,
                'reason': 'LLM ì—†ì´ ê¸°ë³¸ ê²€ì¦ë§Œ ìˆ˜í–‰'
            }
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_validation_prompt(node, parent, siblings, children)
        
        # LLM í˜¸ì¶œ
        response = self._call_llm(prompt)
        
        # ì‘ë‹µ íŒŒì‹±
        result = self._parse_validation_response(response)
        
        return result
    
    def validate_and_fix(self, node: Dict, parent: Optional[Dict] = None,
                        siblings: List[Dict] = None,
                        children: List[Dict] = None) -> Tuple[Dict, bool]:
        """
        Role ê²€ì¦ í›„ ë¬¸ì œê°€ ìˆìœ¼ë©´ ìë™ ìˆ˜ì •
        
        Args:
            node: í˜„ì¬ ë…¸ë“œ
            parent: ë¶€ëª¨ ë…¸ë“œ
            siblings: í˜•ì œ ë…¸ë“œë“¤
            children: ìì‹ ë…¸ë“œë“¤
        
        Returns:
            (ê²€ì¦ ê²°ê³¼, ìˆ˜ì • ì—¬ë¶€) íŠœí”Œ
        """
        result = self.validate_role(node, parent, siblings, children)
        
        modified = False
        
        # â­ ë¨¼ì €: ìì‹ ê·¸ë£¹ ì•ˆì— ìˆëŠ” "ì „ì²´ ë®ëŠ” Background"ë¥¼ ìŠ¹ê²©
        if children:
            bg_promoted = self._promote_full_coverage_background(node)
            if bg_promoted:
                modified = True
                # children ëª©ë¡ ê°±ì‹ 
                children = node.get('children', [])
        
        if not result.get('is_valid', True):
            # ìˆ˜ì • ì œì•ˆì´ ìˆìœ¼ë©´ ì ìš©
            for suggestion in result.get('suggestions', []):
                action = suggestion.get('action')
                
                if action == 'change_role':
                    # Role ë³€ê²½
                    target_id = suggestion.get('target_id')
                    suggested_role = suggestion.get('suggested_role')
                    
                    if target_id == node.get('id') and suggested_role:
                        old_role = node.get('role', '')
                        node['role'] = suggested_role
                        modified = True
                        print(f"      ğŸ”§ Role ìˆ˜ì •: {old_role} â†’ {suggested_role}")
                    
                    # ìì‹ ë…¸ë“œì˜ Role ìˆ˜ì •
                    elif children and suggested_role:
                        for child in children:
                            if child.get('id') == target_id:
                                old_role = child.get('role', '')
                                child['role'] = suggested_role
                                modified = True
                                print(f"      ğŸ”§ ìì‹ Role ìˆ˜ì •: {target_id} ({old_role} â†’ {suggested_role})")
                                break
                
                elif action == 'wrap_with_group':
                    # Groupìœ¼ë¡œ ë¬¶ê¸° - ì´ìŠˆ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
                    target_ids = suggestion.get('target_ids', [])
                    issue_type = suggestion.get('issue_type', '')
                    
                    if target_ids and children:
                        # Background ì¤‘ë³µ ë¬¸ì œ: ì „ì²´ êµ¬ì¡° ì¬í¸ì„±
                        if issue_type == 'background_duplicate':
                            new_group_role = suggestion.get('new_group_role', 'Role.LayoutContainer.Decoration')
                            success = self._wrap_children_with_group(node, children, target_ids, new_group_role, suggestion)
                            if success:
                                modified = True
                                print(f"      ğŸ”§ Background ì¤‘ë³µ í•´ê²°: Groupìœ¼ë¡œ ë¬¶ìŒ")
                        # Decoration ê²¹ì¹¨ ë¬¸ì œ: Decorationë§Œ ë¬¶ê¸°
                        else:
                            success = self._wrap_decorations_only(node, target_ids, suggestion)
                            if success:
                                modified = True
                
                elif action == 'restructure_overlapping':
                    # ê²¹ì¹˜ëŠ” Decorationë§Œ êµ¬ì¡° ì¬í¸ì„± (BackgroundëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
                    if children:
                        success = self._restructure_overlapping_elements(node, children, suggestion)
                        if success:
                            modified = True
        
        # ê²€ì¦ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        node['_role_validation'] = {
            'is_valid': result.get('is_valid', True),
            'confidence': result.get('confidence', 0.0),
            'issues_count': len(result.get('issues', []))
        }
        
        return result, modified
    
    def _promote_full_coverage_background(self, node: Dict) -> bool:
        """
        ìì‹ Group ì•ˆì— ìˆëŠ” "ì „ì²´ë¥¼ ë®ëŠ” Background"ë¥¼ í˜„ì¬ ë…¸ë“œ ë ˆë²¨ë¡œ ìŠ¹ê²©
        
        ì˜ˆ: group_card1 ì•ˆì˜ group_card1_icon ì•ˆì— ìˆëŠ” í° í°ìƒ‰ ë°°ê²½ â†’
            group_card1ì˜ ì§ì ‘ ìì‹ìœ¼ë¡œ ì´ë™
        
        ê·œì¹™:
        - ìì‹ Group ì•ˆì˜ Backgroundê°€
        - ë¶€ëª¨ ë…¸ë“œì˜ 90% ì´ìƒì„ ì°¨ì§€í•˜ë©´
        - í•´ë‹¹ Backgroundë¥¼ ë¶€ëª¨ì˜ ì§ì ‘ ìì‹ìœ¼ë¡œ ìŠ¹ê²©
        """
        children = node.get('children', [])
        if not children:
            return False
        
        node_pos = node.get('position', {})
        node_area = node_pos.get('width', 0) * node_pos.get('height', 0)
        if node_area == 0:
            return False
        
        modified = False
        
        for child in children:
            # Group/VStack/HStack íƒ€ì…ì˜ ìì‹ë§Œ ê²€ì‚¬
            if child.get('type') not in ['Group', 'VStack', 'HStack']:
                continue
            
            child_children = child.get('children', [])
            if not child_children:
                continue
            
            # ìì‹ ê·¸ë£¹ ì•ˆì—ì„œ Background ì°¾ê¸°
            bg_to_promote = None
            bg_index = -1
            
            for i, grandchild in enumerate(child_children):
                if 'Background' in grandchild.get('role', ''):
                    gc_pos = grandchild.get('position', {})
                    gc_area = gc_pos.get('width', 0) * gc_pos.get('height', 0)
                    
                    # ë¶€ëª¨ ë…¸ë“œì˜ 70% ì´ìƒì„ ì°¨ì§€í•˜ë©´ ìŠ¹ê²© ëŒ€ìƒ
                    if gc_area >= node_area * 0.7:
                        bg_to_promote = grandchild
                        bg_index = i
                        break
            
            if bg_to_promote and bg_index >= 0:
                # ìì‹ ê·¸ë£¹ì—ì„œ Background ì œê±°
                child_children.pop(bg_index)
                
                # Backgroundì˜ role í™•ì¸ ë° ì„¤ì •
                bg_to_promote['role'] = 'Role.Element.Background'
                
                # í˜„ì¬ ë…¸ë“œì˜ ì²« ë²ˆì§¸ ìì‹ìœ¼ë¡œ ì‚½ì… (ë°°ê²½ì´ë¯€ë¡œ ë§¨ ë’¤ì— ë Œë”ë§)
                children.insert(0, bg_to_promote)
                
                print(f"      â¬†ï¸ Background ìŠ¹ê²©: {bg_to_promote.get('id', '')[:8]}...")
                print(f"         {child.get('id', '')} â†’ {node.get('id', '')} ë ˆë²¨ë¡œ ì´ë™")
                
                modified = True
        
        return modified
    
    def _wrap_children_with_group(self, parent_node: Dict, children: List[Dict], 
                                   target_ids: List[str], new_group_role: str,
                                   suggestion: Dict) -> bool:
        """
        ì§€ì •ëœ ìì‹ë“¤ì„ ìƒˆ Groupìœ¼ë¡œ ë¬¶ê¸° (ì¤‘ì²© ê²¹ì¹¨ë„ ì¬ê·€ ì²˜ë¦¬)
        
        Args:
            parent_node: ë¶€ëª¨ ë…¸ë“œ
            children: í˜„ì¬ ìì‹ ë…¸ë“œë“¤ (ë¶€ëª¨ì˜ children ì°¸ì¡°)
            target_ids: ë¬¶ì„ ë…¸ë“œ ID ë¦¬ìŠ¤íŠ¸
            new_group_role: ìƒˆ Groupì˜ Role
            suggestion: LLM ì œì•ˆ (ì¶”ê°€ ì •ë³´ í¬í•¨)
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        import uuid
        
        # ë¬¶ì„ ë…¸ë“œë“¤ ì°¾ê¸°
        nodes_to_wrap = []
        indices_to_remove = []
        
        parent_children = parent_node.get('children', [])
        
        for i, child in enumerate(parent_children):
            if child.get('id') in target_ids:
                nodes_to_wrap.append(child)
                indices_to_remove.append(i)
        
        if len(nodes_to_wrap) < 2:
            return False  # ë¬¶ì„ ë…¸ë“œê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
        
        # ê²¹ì¹¨ ê·¸ë£¹ ë¶„ì„ ë° ì¤‘ì²© êµ¬ì¡° ìƒì„±
        structured_children = self._create_nested_overlap_structure(nodes_to_wrap)
        
        # position ê³„ì‚° (ë¬¶ì´ëŠ” ë…¸ë“œë“¤ì˜ bounding box)
        positions = [n.get('position', {}) for n in nodes_to_wrap if n.get('position')]
        min_x, min_y, group_width, group_height = 0, 0, 0, 0
        if positions:
            min_x = min(p.get('x', 0) for p in positions)
            min_y = min(p.get('y', 0) for p in positions)
            max_x = max(p.get('x', 0) + p.get('width', 0) for p in positions)
            max_y = max(p.get('y', 0) + p.get('height', 0) for p in positions)
            group_width = max_x - min_x
            group_height = max_y - min_y
        
        # ìƒˆ Group ìƒì„± (í•„ìˆ˜ ì†ì„± í¬í•¨)
        new_group = {
            'id': f"auto_group_{uuid.uuid4().hex[:8]}",
            'type': 'Group',
            'role': new_group_role,
            'children': structured_children,
            '_auto_generated': True,
            '_reason': suggestion.get('reason', 'LLM ì œì•ˆì— ì˜í•œ ìë™ ê·¸ë£¹í™”'),
            'position': {
                'x': min_x,
                'y': min_y,
                'width': group_width,
                'height': group_height
            },
            # í•„ìˆ˜ ì†ì„±ë“¤ ì¶”ê°€
            'resizing': 'hug * hug',
            'direction': 'vertical',
            'alignment': 'center',
            'verticalAlignment': 'center',
            'horizontalAlignment': 'center',
            'padding': {
                'top': 0,
                'right': 0,
                'bottom': 0,
                'left': 0
            },
            'gap': 0
        }
        
        # ê¸°ì¡´ childrenì—ì„œ ì œê±° (ì—­ìˆœìœ¼ë¡œ ì œê±°í•´ì•¼ ì¸ë±ìŠ¤ ê¼¬ì´ì§€ ì•ŠìŒ)
        for idx in sorted(indices_to_remove, reverse=True):
            parent_children.pop(idx)
        
        # ìƒˆ Groupì„ childrenì˜ ì²˜ìŒì— ì‚½ì… (ë°°ê²½ ë ˆì´ì–´ë‹ˆê¹Œ)
        parent_children.insert(0, new_group)
        
        return True
    
    def _create_nested_overlap_structure(self, nodes: List[Dict]) -> List[Dict]:
        """
        ê²¹ì¹˜ëŠ” ë…¸ë“œë“¤ì„ ì¤‘ì²© êµ¬ì¡°ë¡œ ë³€í™˜
        
        ì•Œê³ ë¦¬ì¦˜:
        1. ë©´ì  ìˆœ ì •ë ¬ (í° ê²ƒ = ë’¤, ì‘ì€ ê²ƒ = ì•)
        2. ê°€ì¥ í° ê²ƒì„ Backgroundë¡œ
        3. ë‚˜ë¨¸ì§€ ì¤‘ ì„œë¡œ ê²¹ì¹˜ëŠ” ê²ƒë“¤ë¼ë¦¬ ë˜ Groupìœ¼ë¡œ ë¬¶ê¸° (ì¬ê·€)
        4. ì•ˆ ê²¹ì¹˜ëŠ” ê²ƒë“¤ì€ Decorationìœ¼ë¡œ ê·¸ëŒ€ë¡œ ì¶”ê°€
        
        Returns:
            ì¤‘ì²© êµ¬ì¡°ê°€ ì ìš©ëœ children ë¦¬ìŠ¤íŠ¸
        """
        import uuid
        
        if len(nodes) < 2:
            return nodes
        
        def get_area(n):
            pos = n.get('position', {})
            return pos.get('width', 0) * pos.get('height', 0)
        
        def boxes_overlap(a: Dict, b: Dict) -> bool:
            """ë‘ positionì´ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸"""
            if not a or not b:
                return False
            a_x1, a_y1 = a.get('x', 0), a.get('y', 0)
            a_x2, a_y2 = a_x1 + a.get('width', 0), a_y1 + a.get('height', 0)
            b_x1, b_y1 = b.get('x', 0), b.get('y', 0)
            b_x2, b_y2 = b_x1 + b.get('width', 0), b_y1 + b.get('height', 0)
            return not (a_x2 <= b_x1 or b_x2 <= a_x1 or a_y2 <= b_y1 or b_y2 <= a_y1)
        
        # ë©´ì  ìˆœ ì •ë ¬ (í° ê²ƒë¶€í„°)
        sorted_nodes = sorted(nodes, key=get_area, reverse=True)
        
        # ê°€ì¥ í° ê²ƒì„ Backgroundë¡œ ì„¤ì •
        background_node = sorted_nodes[0]
        if background_node.get('role', '').startswith('Role.Element'):
            background_node['role'] = 'Role.Element.Background'
        
        remaining_nodes = sorted_nodes[1:]
        
        if not remaining_nodes:
            return [background_node]
        
        # ë‚˜ë¨¸ì§€ ë…¸ë“œë“¤ ì¤‘ ê²¹ì¹˜ëŠ” ê²ƒë“¤ ê·¸ë£¹í™”
        result = [background_node]
        
        # ê° ë…¸ë“œê°€ ë‹¤ë¥¸ ë…¸ë“œì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ ê·¸ë£¹í™”
        processed = set()
        
        for i, node in enumerate(remaining_nodes):
            if node.get('id') in processed:
                continue
            
            # ì´ ë…¸ë“œì™€ ê²¹ì¹˜ëŠ” ë‹¤ë¥¸ ë…¸ë“œë“¤ ì°¾ê¸°
            overlapping = [node]
            for j, other in enumerate(remaining_nodes):
                if i != j and other.get('id') not in processed:
                    if boxes_overlap(node.get('position'), other.get('position')):
                        overlapping.append(other)
                        processed.add(other.get('id'))
            
            processed.add(node.get('id'))
            
            if len(overlapping) > 1:
                # ê²¹ì¹˜ëŠ” ê²ƒë“¤ë¼ë¦¬ ì¤‘ì²© Group ìƒì„± (ì¬ê·€!)
                nested_children = self._create_nested_overlap_structure(overlapping)
                
                # position ê³„ì‚°
                positions = [n.get('position', {}) for n in overlapping if n.get('position')]
                min_x, min_y, group_width, group_height = 0, 0, 0, 0
                if positions:
                    min_x = min(p.get('x', 0) for p in positions)
                    min_y = min(p.get('y', 0) for p in positions)
                    max_x = max(p.get('x', 0) + p.get('width', 0) for p in positions)
                    max_y = max(p.get('y', 0) + p.get('height', 0) for p in positions)
                    group_width = max_x - min_x
                    group_height = max_y - min_y
                
                # ìƒˆ ì¤‘ì²© Group (í•„ìˆ˜ ì†ì„± í¬í•¨)
                nested_group = {
                    'id': f"auto_nested_{uuid.uuid4().hex[:8]}",
                    'type': 'Group',
                    'role': 'Role.LayoutContainer.Decoration',
                    'children': nested_children,
                    '_auto_generated': True,
                    '_reason': 'ì¤‘ì²© ê²¹ì¹¨ì— ì˜í•œ ìë™ ê·¸ë£¹í™”',
                    'position': {
                        'x': min_x,
                        'y': min_y,
                        'width': group_width,
                        'height': group_height
                    },
                    # í•„ìˆ˜ ì†ì„±ë“¤ ì¶”ê°€
                    'resizing': 'hug * hug',
                    'direction': 'vertical',
                    'alignment': 'center',
                    'verticalAlignment': 'center',
                    'horizontalAlignment': 'center',
                    'padding': {
                        'top': 0,
                        'right': 0,
                        'bottom': 0,
                        'left': 0
                    },
                    'gap': 0
                }
                
                result.append(nested_group)
            else:
                # ì•ˆ ê²¹ì¹˜ëŠ” ë‹¨ì¼ ë…¸ë“œëŠ” Decorationìœ¼ë¡œ
                if 'Background' in node.get('role', ''):
                    node['role'] = 'Role.Element.Decoration'
                result.append(node)
        
        return result
    
    def _restructure_overlapping_elements(self, parent_node: Dict, children: List[Dict],
                                          suggestion: Dict) -> bool:
        """
        ê²¹ì¹˜ëŠ” ìš”ì†Œë“¤ì˜ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ì¬í¸ì„±
        
        í•µì‹¬ ê·œì¹™:
        - BackgroundëŠ” 1ê°œë¿ì´ë©´ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        - Decorationë¼ë¦¬ ê²¹ì¹˜ëŠ” ê²ƒë§Œ Groupìœ¼ë¡œ ë¬¶ê¸°
        - ì•ˆ ê²¹ì¹˜ëŠ” ìš”ì†Œë“¤ì€ ì›ë˜ ìœ„ì¹˜ ìœ ì§€
        """
        parent_children = parent_node.get('children', [])
        if len(parent_children) < 2:
            return False
        
        # Decorationë“¤ë§Œ ì¶”ì¶œ
        decorations = [
            n for n in parent_children 
            if 'Decoration' in n.get('role', '')
        ]
        
        if len(decorations) < 2:
            return False  # Decorationì´ 2ê°œ ë¯¸ë§Œì´ë©´ ê²¹ì¹¨ ì²˜ë¦¬ ë¶ˆí•„ìš”
        
        # Decorationë“¤ ì‚¬ì´ì—ì„œë§Œ ê²¹ì¹¨ ê°ì§€
        overlapping_groups = self._detect_overlapping_groups_decorations_only(decorations)
        
        if not overlapping_groups:
            return False
        
        modified = False
        for group_ids in overlapping_groups:
            if len(group_ids) >= 2:
                success = self._wrap_decorations_only(
                    parent_node, 
                    group_ids,
                    {'reason': 'ê²¹ì¹˜ëŠ” Decorationë“¤ì„ Groupìœ¼ë¡œ ë¬¶ê¸°'}
                )
                if success:
                    modified = True
        
        return modified
    
    def _detect_overlapping_groups_decorations_only(self, decorations: List[Dict]) -> List[List[str]]:
        """
        Decorationë“¤ ì‚¬ì´ì—ì„œë§Œ ê²¹ì¹¨ ê°ì§€
        """
        def boxes_overlap(a: Dict, b: Dict) -> bool:
            if not a or not b:
                return False
            a_x1, a_y1 = a.get('x', 0), a.get('y', 0)
            a_x2, a_y2 = a_x1 + a.get('width', 0), a_y1 + a.get('height', 0)
            b_x1, b_y1 = b.get('x', 0), b.get('y', 0)
            b_x2, b_y2 = b_x1 + b.get('width', 0), b_y1 + b.get('height', 0)
            return not (a_x2 <= b_x1 or b_x2 <= a_x1 or a_y2 <= b_y1 or b_y2 <= a_y1)
        
        if len(decorations) < 2:
            return []
        
        # Union-Find
        parent_map = {n.get('id'): n.get('id') for n in decorations}
        
        def find(x):
            if parent_map[x] != x:
                parent_map[x] = find(parent_map[x])
            return parent_map[x]
        
        def union(x, y):
            px, py = find(x), find(y)
            if px != py:
                parent_map[px] = py
        
        # ê²¹ì¹˜ëŠ” ìŒ ì°¾ê¸°
        for i in range(len(decorations)):
            for j in range(i + 1, len(decorations)):
                n1, n2 = decorations[i], decorations[j]
                if boxes_overlap(n1.get('position'), n2.get('position')):
                    union(n1.get('id'), n2.get('id'))
        
        # ê·¸ë£¹ë³„ë¡œ ëª¨ìœ¼ê¸°
        groups = {}
        for n in decorations:
            root = find(n.get('id'))
            if root not in groups:
                groups[root] = []
            groups[root].append(n.get('id'))
        
        # 2ê°œ ì´ìƒì¸ ê·¸ë£¹ë§Œ ë°˜í™˜
        return [ids for ids in groups.values() if len(ids) >= 2]
    
    def _wrap_decorations_only(self, parent_node: Dict, target_ids: List[str], 
                               suggestion: Dict) -> bool:
        """
        Decorationë“¤ë§Œ Groupìœ¼ë¡œ ë¬¶ê¸°
        
        í•µì‹¬ ê·œì¹™:
        - ì›ë˜ Roleì´ Backgroundì¸ ìš”ì†ŒëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ!
        - ìì‹ë“¤ì˜ positionì„ ìƒˆ Group ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜ (ë£°ë² ì´ìŠ¤)
        - raw_dataê°€ ë¶€ëª¨ ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œì´ë¯€ë¡œ, ìƒˆ Groupë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        """
        import uuid
        
        parent_children = parent_node.get('children', [])
        
        # ë¬¶ì„ Decorationë“¤ ì°¾ê¸° (ì‹¤ì œë¡œ Decorationì¸ ê²ƒë§Œ!)
        nodes_to_wrap = []
        indices_to_remove = []
        
        for i, child in enumerate(parent_children):
            if child.get('id') in target_ids:
                # BackgroundëŠ” ì œì™¸! Decorationë§Œ ë¬¶ìŒ
                if 'Background' in child.get('role', ''):
                    continue
                nodes_to_wrap.append(child)
                indices_to_remove.append(i)
        
        if len(nodes_to_wrap) < 2:
            return False
        
        # ìƒˆ Groupì˜ position ê³„ì‚° (bounding box)
        positions = [n.get('position', {}) for n in nodes_to_wrap if n.get('position')]
        if not positions:
            return False
        
        # Groupì˜ ìœ„ì¹˜ = ìì‹ë“¤ì˜ bounding box
        group_x = min(p.get('x', 0) for p in positions)
        group_y = min(p.get('y', 0) for p in positions)
        max_x = max(p.get('x', 0) + p.get('width', 0) for p in positions)
        max_y = max(p.get('y', 0) + p.get('height', 0) for p in positions)
        group_width = max_x - group_x
        group_height = max_y - group_y
        
        # â­ ë£°ë² ì´ìŠ¤: ìì‹ë“¤ì˜ positionì„ ìƒˆ Group ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
        for node in nodes_to_wrap:
            pos = node.get('position', {})
            if pos:
                node['position'] = {
                    'x': pos.get('x', 0) - group_x,
                    'y': pos.get('y', 0) - group_y,
                    'width': pos.get('width', 0),
                    'height': pos.get('height', 0)
                }
        
        # ë©´ì  ìˆœ ì •ë ¬ (í° ê²ƒì´ ë’¤ì— = Background ì—­í• )
        def get_area(n):
            pos = n.get('position', {})
            return pos.get('width', 0) * pos.get('height', 0)
        
        sorted_nodes = sorted(nodes_to_wrap, key=get_area, reverse=True)
        
        # ìƒˆ Group ì•ˆì—ì„œë§Œ Background/Decoration í• ë‹¹
        for i, node in enumerate(sorted_nodes):
            if i == 0:
                node['role'] = 'Role.Element.Background'
            else:
                node['role'] = 'Role.Element.Decoration'
        
        # ìƒˆ Group ìƒì„± (í•„ìˆ˜ ì†ì„± í¬í•¨)
        new_group = {
            'id': f"auto_deco_group_{uuid.uuid4().hex[:8]}",
            'type': 'Group',
            'role': 'Role.LayoutContainer.Decoration',
            'children': sorted_nodes,
            '_auto_generated': True,
            '_reason': suggestion.get('reason', 'ê²¹ì¹˜ëŠ” Decoration ê·¸ë£¹í™”'),
            'position': {
                'x': group_x,
                'y': group_y,
                'width': group_width,
                'height': group_height
            },
            # í•„ìˆ˜ ì†ì„±ë“¤ ì¶”ê°€
            'resizing': 'hug * hug',  # Decoration ê·¸ë£¹ì€ ë‚´ìš©ë¬¼ í¬ê¸°ì— ë§ì¶¤
            'direction': 'vertical',
            'alignment': 'center',
            'verticalAlignment': 'center',
            'horizontalAlignment': 'center',
            'padding': {
                'top': 0,
                'right': 0,
                'bottom': 0,
                'left': 0
            },
            'gap': 0
        }
        
        # ê¸°ì¡´ childrenì—ì„œ ì œê±° (ì—­ìˆœ)
        for idx in sorted(indices_to_remove, reverse=True):
            parent_children.pop(idx)
        
        # ìƒˆ Group ì‚½ì… (ì›ë˜ ìœ„ì¹˜ì—)
        insert_idx = min(indices_to_remove) if indices_to_remove else 0
        parent_children.insert(insert_idx, new_group)
        
        print(f"         ğŸ“¦ Decoration ê·¸ë£¹í™”: {[n.get('id')[:8] for n in nodes_to_wrap]}")
        print(f"            Group position: ({group_x:.1f}, {group_y:.1f})")
        print(f"            ìì‹ ìƒëŒ€ì¢Œí‘œ ë³€í™˜ ì™„ë£Œ")
        
        return True
    
    def _detect_overlapping_groups(self, nodes: List[Dict]) -> List[List[str]]:
        """
        ê²¹ì¹˜ëŠ” ë…¸ë“œë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
        """
        def boxes_overlap(a: Dict, b: Dict) -> bool:
            """ë‘ positionì´ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸"""
            if not a or not b:
                return False
            
            a_x1, a_y1 = a.get('x', 0), a.get('y', 0)
            a_x2, a_y2 = a_x1 + a.get('width', 0), a_y1 + a.get('height', 0)
            b_x1, b_y1 = b.get('x', 0), b.get('y', 0)
            b_x2, b_y2 = b_x1 + b.get('width', 0), b_y1 + b.get('height', 0)
            
            # ê²¹ì¹˜ì§€ ì•ŠëŠ” ì¡°ê±´ì˜ ë¶€ì •
            return not (a_x2 <= b_x1 or b_x2 <= a_x1 or a_y2 <= b_y1 or b_y2 <= a_y1)
        
        # Backgroundë‚˜ Decorationë§Œ í•„í„°ë§
        target_nodes = [
            n for n in nodes 
            if 'Background' in n.get('role', '') or 'Decoration' in n.get('role', '')
        ]
        
        if len(target_nodes) < 2:
            return []
        
        # Union-Findë¡œ ê²¹ì¹˜ëŠ” ê·¸ë£¹ ì°¾ê¸°
        parent_map = {n.get('id'): n.get('id') for n in target_nodes}
        
        def find(x):
            if parent_map[x] != x:
                parent_map[x] = find(parent_map[x])
            return parent_map[x]
        
        def union(x, y):
            px, py = find(x), find(y)
            if px != py:
                parent_map[px] = py
        
        # ê²¹ì¹˜ëŠ” ìŒ ì°¾ê¸°
        for i in range(len(target_nodes)):
            for j in range(i + 1, len(target_nodes)):
                n1, n2 = target_nodes[i], target_nodes[j]
                if boxes_overlap(n1.get('position'), n2.get('position')):
                    union(n1.get('id'), n2.get('id'))
        
        # ê·¸ë£¹ë³„ë¡œ ëª¨ìœ¼ê¸°
        groups = {}
        for n in target_nodes:
            root = find(n.get('id'))
            if root not in groups:
                groups[root] = []
            groups[root].append(n.get('id'))
        
        # 2ê°œ ì´ìƒì¸ ê·¸ë£¹ë§Œ ë°˜í™˜
        return [ids for ids in groups.values() if len(ids) >= 2]
    
    def _create_validation_prompt(self, node: Dict, parent: Optional[Dict],
                                  siblings: List[Dict], children: List[Dict]) -> str:
        """
        Role ê²€ì¦ì„ ìœ„í•œ LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        # ë…¸ë“œ ì •ë³´ ìˆ˜ì§‘ (position í¬í•¨!)
        node_info = {
            'id': node.get('id'),
            'role': node.get('role', ''),
            'type': node.get('type', ''),
            'content': node.get('content', '')[:200] if node.get('content') else '',
            'position': node.get('position'),  # ê²¹ì¹¨ íŒë‹¨ìš©!
            'has_children': len(node.get('children', [])) > 0,
            'children_count': len(node.get('children', []))
        }
        
        # ë¶€ëª¨ ì •ë³´
        parent_info = None
        if parent:
            parent_info = {
                'id': parent.get('id'),
                'role': parent.get('role', ''),
                'type': parent.get('type', '')
            }
        
        # í˜•ì œ ì •ë³´ (ê°™ì€ Roleì„ ê°€ì§„ í˜•ì œ ìˆ˜ + position í¬í•¨)
        siblings_info = []
        same_role_count = 0
        if siblings:
            current_role = node.get('role', '')
            for s in siblings[:5]:  # ìµœëŒ€ 5ê°œ
                sibling_role = s.get('role', '')
                if sibling_role == current_role:
                    same_role_count += 1
                siblings_info.append({
                    'id': s.get('id'),
                    'role': sibling_role,
                    'type': s.get('type', ''),
                    'position': s.get('position')  # ê²¹ì¹¨ íŒë‹¨ìš©!
                })
        
        siblings_summary = {
            'siblings': siblings_info,
            'same_role_count': same_role_count,
            'total_siblings': len(siblings) if siblings else 0
        }
        
        # ìì‹ ë…¸ë“œ ì •ë³´ (Role ë¶„í¬ + position í¬í•¨ - ê²¹ì¹¨ íŒë‹¨ìš©!)
        children_info = []
        children_role_counts = {}
        if children:
            for c in children[:10]:  # ìµœëŒ€ 10ê°œ
                child_role = c.get('role', '')
                children_role_counts[child_role] = children_role_counts.get(child_role, 0) + 1
                children_info.append({
                    'id': c.get('id'),
                    'role': child_role,
                    'type': c.get('type', ''),
                    'content': c.get('content', '')[:100] if c.get('content') else '',
                    'position': c.get('position')  # ê²¹ì¹¨ íŒë‹¨ìš©!
                })
        
        children_summary = {
            'children': children_info,
            'role_distribution': children_role_counts,
            'total_children': len(children) if children else 0
        }
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = {
            'node_info': node_info,
            'parent_info': parent_info,
            'siblings_info': siblings_summary,
            'children_info': children_summary
        }
        
        prompt = self.prompt_loader.get_prompt('role_validation', context)
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)"""
        config = self.prompt_loader.get_llm_config('role_validation')
        
        if hasattr(self.llm_client, 'chat'):
            # OpenAI ìŠ¤íƒ€ì¼
            system_message = self.prompt_loader._prompts.get('role_validation', {}).get('system_role', '')
            
            # ë©€í‹°ëª¨ë‹¬: ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì „ì†¡
            if self.reference_image_base64:
                mime_type = get_image_mime_type(self.reference_image_path)
                user_content = [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{self.reference_image_base64}",
                            "detail": "high"
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            else:
                user_content = prompt
            
            response = self.llm_client.chat.completions.create(
                model=config.get('model', 'gpt-4o'),  # ë©€í‹°ëª¨ë‹¬ì€ gpt-4o í•„ìš”
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_content}
                ],
                temperature=config.get('temperature', 0.1),
                max_tokens=config.get('max_tokens', 500)
            )
            return response.choices[0].message.content
        elif hasattr(self.llm_client, 'complete'):
            return self.llm_client.complete(prompt)
        else:
            return '{"is_valid": true, "current_role": "", "issues": [], "suggestions": [], "confidence": 0.5, "reason": "ê¸°ë³¸ ê²€ì¦"}'
    
    def _parse_validation_response(self, response: str) -> Dict:
        """LLM ì‘ë‹µì—ì„œ ê²€ì¦ ê²°ê³¼ ì¶”ì¶œ"""
        try:
            # JSON ì¶”ì¶œ
            if '```json' in response:
                json_start = response.find('```json') + 7
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            elif '```' in response:
                json_start = response.find('```') + 3
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
            
            result = json.loads(json_str)
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
            return {
                'is_valid': result.get('is_valid', True),
                'current_role': result.get('current_role', ''),
                'issues': result.get('issues', []),
                'suggestions': result.get('suggestions', []),
                'confidence': result.get('confidence', 0.5),
                'reason': result.get('reason', '')
            }
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            print(f"âš ï¸ Role Validation íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {
                'is_valid': True,
                'current_role': '',
                'issues': [],
                'suggestions': [],
                'confidence': 0.0,
                'reason': f'íŒŒì‹± ì˜¤ë¥˜: {str(e)}'
            }
    
    def generate_validation_report(self, all_results: List[Dict]) -> Dict:
        """
        ì „ì²´ ê²€ì¦ ê²°ê³¼ì— ëŒ€í•œ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            all_results: ëª¨ë“  ë…¸ë“œì˜ ê²€ì¦ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì¢…í•© ë¦¬í¬íŠ¸
        """
        total_nodes = len(all_results)
        valid_nodes = sum(1 for r in all_results if r.get('is_valid', True))
        invalid_nodes = total_nodes - valid_nodes
        
        # ì´ìŠˆ íƒ€ì…ë³„ ì§‘ê³„
        issue_types = {}
        all_issues = []
        for r in all_results:
            for issue in r.get('issues', []):
                issue_type = issue.get('type', 'unknown')
                issue_types[issue_type] = issue_types.get(issue_type, 0) + 1
                all_issues.append(issue)
        
        # ì‹¬ê°ë„ë³„ ì§‘ê³„
        severity_counts = {'error': 0, 'warning': 0, 'info': 0}
        for issue in all_issues:
            severity = issue.get('severity', 'info')
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # í‰ê·  ì‹ ë¢°ë„
        confidences = [r.get('confidence', 0.0) for r in all_results]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        
        return {
            'summary': {
                'total_nodes': total_nodes,
                'valid_nodes': valid_nodes,
                'invalid_nodes': invalid_nodes,
                'validation_rate': valid_nodes / total_nodes if total_nodes > 0 else 0.0,
                'average_confidence': avg_confidence
            },
            'issues_by_type': issue_types,
            'issues_by_severity': severity_counts,
            'total_issues': len(all_issues),
            'all_issues': all_issues[:20]  # ìƒìœ„ 20ê°œë§Œ
        }


class LLMCoordinatorAgent:
    """
    Agent 5: LLM ê¸°ë°˜ Coordinator (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
    - ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨
    - ê° LLM ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ
    - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìµœì í™”
    - ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ í†µí•œ ì‹œê°ì  ë¶„ì„ ì§€ì›
    """
    
    def __init__(self, llm_client, use_partial_loading: bool = False, 
                 prompt_loader: Optional[PromptLoader] = None,
                 enable_role_validation: bool = True,
                 reference_image_path: Optional[str] = None):
        """
        Args:
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸
            use_partial_loading: ë¶€ë¶„ ë¡œë“œ ì‚¬ìš© ì—¬ë¶€
            prompt_loader: í”„ë¡¬í”„íŠ¸ ë¡œë” (Noneì´ë©´ ìë™ ìƒì„±)
            enable_role_validation: Role ê²€ì¦ í™œì„±í™” ì—¬ë¶€
            reference_image_path: ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ (ë©€í‹°ëª¨ë‹¬ ë¶„ì„ìš©)
        """
        self.llm_client = llm_client
        self.prompt_loader = prompt_loader or PromptLoader()
        
        # ëª¨ë“  ì—ì´ì „íŠ¸ì— prompt_loader ì „ë‹¬ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
        self.role_validator = LLMRoleValidatorAgent(
            llm_client, self.prompt_loader, reference_image_path
        )
        self.rule_analyzer = LLMRuleAnalyzerAgent(llm_client, self.prompt_loader)
        self.layout_analyzer = LLMLayoutAnalyzerAgent(llm_client, self.prompt_loader)
        self.alignment_enricher = LLMAlignmentEnricherAgent(llm_client, self.prompt_loader)
        
        self.use_partial_loading = use_partial_loading
        self.enable_role_validation = enable_role_validation
        self.validation_results = []  # ê²€ì¦ ê²°ê³¼ ìˆ˜ì§‘ìš©
        self.reference_image_path = reference_image_path
    
    def process(self, raw_data: Dict, simplified_structure: Dict,
                target_id: Optional[str] = None) -> Dict:
        """
        ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (LLM ê¸°ë°˜)
        
        Args:
            raw_data: ì „ì²´ raw_data ë˜ëŠ” ì„œë¸ŒíŠ¸ë¦¬
            simplified_structure: ì „ì²´ simplified_structure ë˜ëŠ” ì„œë¸ŒíŠ¸ë¦¬
            target_id: íŠ¹ì • ë…¸ë“œë§Œ ì²˜ë¦¬í•  ê²½ìš° í•´ë‹¹ id
        
        Returns:
            ì²˜ë¦¬ëœ JSON
        """
        # target_idê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ì„œë¸ŒíŠ¸ë¦¬ë§Œ ì²˜ë¦¬
        if target_id and self.use_partial_loading:
            raw_data = extract_subtree(raw_data, target_id) or raw_data
            simplified_structure = extract_subtree(simplified_structure, target_id) or simplified_structure
        
        # raw_dataë¥¼ ë³µì‚¬í•˜ì—¬ ì‘ì—…
        result = deepcopy(raw_data)
        
        # ê²€ì¦ ê²°ê³¼ ì´ˆê¸°í™”
        self.validation_results = []
        
        # íŠ¸ë¦¬ë¥¼ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
        self._process_node(result, simplified_structure, None, [], True)
        
        # Role ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± (í™œì„±í™”ëœ ê²½ìš°)
        if self.enable_role_validation and self.validation_results:
            report = self.role_validator.generate_validation_report(self.validation_results)
            result['_validation_report'] = report
            self._print_validation_summary(report)
        
        return result
    
    def _print_validation_summary(self, report: Dict):
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        summary = report.get('summary', {})
        print("\n" + "=" * 60)
        print("ğŸ“Š Role ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"   ì´ ë…¸ë“œ ìˆ˜: {summary.get('total_nodes', 0)}")
        print(f"   âœ… ìœ íš¨í•œ ë…¸ë“œ: {summary.get('valid_nodes', 0)}")
        print(f"   âŒ ë¬¸ì œ ìˆëŠ” ë…¸ë“œ: {summary.get('invalid_nodes', 0)}")
        print(f"   ğŸ“ˆ ê²€ì¦ í†µê³¼ìœ¨: {summary.get('validation_rate', 0):.1%}")
        print(f"   ğŸ¯ í‰ê·  ì‹ ë¢°ë„: {summary.get('average_confidence', 0):.1%}")
        
        issues_by_severity = report.get('issues_by_severity', {})
        if any(issues_by_severity.values()):
            print("\n   ì´ìŠˆ ì‹¬ê°ë„:")
            if issues_by_severity.get('error', 0) > 0:
                print(f"      ğŸ”´ Error: {issues_by_severity['error']}ê°œ")
            if issues_by_severity.get('warning', 0) > 0:
                print(f"      ğŸŸ¡ Warning: {issues_by_severity['warning']}ê°œ")
            if issues_by_severity.get('info', 0) > 0:
                print(f"      ğŸ”µ Info: {issues_by_severity['info']}ê°œ")
        print("=" * 60)
    
    def _process_node(self, raw_node: Dict, simplified_node: Dict,
                     parent: Optional[Dict], siblings: List[Dict],
                     is_root: bool = False):
        """
        ë…¸ë“œë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ë§¤ìš° êµ¬ì²´ì ì¸ ê³¼ì •)
        
        ì´ ë©”ì„œë“œëŠ” ê° ë…¸ë“œì— ëŒ€í•´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤:
        
        0ë‹¨ê³„: Role ê²€ì¦ (í™œì„±í™”ëœ ê²½ìš°)
        1ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        2ë‹¨ê³„: LLM Rule Analyzer í˜¸ì¶œ â†’ resizing ê²°ì •
        3ë‹¨ê³„: LLM Layout Analyzer í˜¸ì¶œ â†’ direction, gap, padding ê²°ì •
        4ë‹¨ê³„: LLM Alignment Enricher í˜¸ì¶œ â†’ alignment ê²°ì •
        5ë‹¨ê³„: ìì‹ ë…¸ë“œ ì¬ê·€ ì²˜ë¦¬
        """
        
        node_id = raw_node.get('id', 'unknown')
        node_role = raw_node.get('role', 'N/A')
        print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {node_id} (Role: {node_role})")
        
        # === 0ë‹¨ê³„: Role ê²€ì¦ (í™œì„±í™”ëœ ê²½ìš°) ===
        structure_changed = False
        if self.enable_role_validation:
            print(f"   ğŸ” [Step 0] Role ê²€ì¦ ì¤‘...")
            try:
                raw_children = raw_node.get('children', [])
                children_count_before = len(raw_children)
                
                validation_result, was_modified = self.role_validator.validate_and_fix(
                    raw_node, parent, siblings, raw_children
                )
                self.validation_results.append(validation_result)
                
                # êµ¬ì¡° ë³€ê²½ ê°ì§€ (children ìˆ˜ê°€ ë³€í–ˆìœ¼ë©´ êµ¬ì¡° ë³€ê²½ë¨)
                children_count_after = len(raw_node.get('children', []))
                structure_changed = children_count_before != children_count_after
                
                if validation_result.get('is_valid'):
                    print(f"      âœ… Role ìœ íš¨ (ì‹ ë¢°ë„: {validation_result.get('confidence', 0):.0%})")
                else:
                    issues_count = len(validation_result.get('issues', []))
                    print(f"      âš ï¸ Role ë¬¸ì œ ë°œê²¬: {issues_count}ê°œ ì´ìŠˆ")
                    for issue in validation_result.get('issues', [])[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                        severity_icon = {'error': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}.get(issue.get('severity', 'info'), 'ğŸ”µ')
                        print(f"         {severity_icon} {issue.get('description', '')}")
                    
                    if was_modified:
                        if structure_changed:
                            print(f"      ğŸ”§ êµ¬ì¡° ë³€ê²½ë¨: {children_count_before}ê°œ â†’ {children_count_after}ê°œ children")
                            # ìƒˆë¡œ ìƒì„±ëœ Group ì •ë³´ ì¶œë ¥
                            for child in raw_node.get('children', []):
                                if child.get('_auto_generated'):
                                    print(f"         ğŸ“¦ ìƒˆ Group ìƒì„±: {child.get('id')} ({len(child.get('children', []))}ê°œ ìš”ì†Œ í¬í•¨)")
                        else:
                            print(f"      ğŸ”§ Roleì´ ìë™ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {raw_node.get('role', '')}")
            except Exception as e:
                import traceback
                print(f"      âš ï¸ Role ê²€ì¦ ì˜¤ë¥˜: {e}")
                traceback.print_exc()
        
        # === 1ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ===
        # ì£¼ë³€ ë…¸ë“œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context_nodes = []
        if hasattr(self, '_collect_context'):
            context_nodes = self._collect_context(raw_node, 10)  # ìµœëŒ€ 10ê°œ ë…¸ë“œ
        
        print(f"   ğŸ“¦ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘: {len(context_nodes)}ê°œ ë…¸ë“œ")
        
        # === 2ë‹¨ê³„: LLM Rule Analyzer â†’ Resizing ê²°ì • ===
        print(f"   ğŸ“ [Step 1] Resizing ê·œì¹™ ê²°ì • ì¤‘...")
        try:
            self.rule_analyzer.determine_resizing(
                raw_node, parent, siblings, context_nodes, is_root
            )
            print(f"      âœ… Resizing: {raw_node.get('resizing', 'N/A')}")
        except Exception as e:
            print(f"      âš ï¸ Resizing ê²°ì • ì˜¤ë¥˜: {e}")
            raw_node['resizing'] = 'fill * fill'  # ê¸°ë³¸ê°’
        
        # === 3ë‹¨ê³„: LLM Layout Analyzer â†’ ë ˆì´ì•„ì›ƒ ì†ì„± ê²°ì • ===
        print(f"   ğŸ“ [Step 2] ë ˆì´ì•„ì›ƒ ì†ì„± ê²°ì • ì¤‘...")
        try:
            self.layout_analyzer.analyze_and_enrich(raw_node, parent)
            print(f"      âœ… Direction: {raw_node.get('direction', 'N/A')}")
            print(f"      âœ… Gap: {raw_node.get('gap', 'N/A')}")
        except Exception as e:
            print(f"      âš ï¸ ë ˆì´ì•„ì›ƒ ê²°ì • ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ ì ìš©
            if 'direction' not in raw_node:
                raw_node['direction'] = 'vertical'
        
        # === 4ë‹¨ê³„: LLM Alignment Enricher â†’ ì •ë ¬ ì†ì„± ê²°ì • ===
        print(f"   ğŸ¯ [Step 3] ì •ë ¬ ì†ì„± ê²°ì • ì¤‘...")
        try:
            self.alignment_enricher.enrich_alignments(raw_node, parent)
            print(f"      âœ… Alignment: {raw_node.get('alignment', 'N/A')}")
        except Exception as e:
            print(f"      âš ï¸ ì •ë ¬ ê²°ì • ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ ì ìš©
            if 'alignment' not in raw_node:
                raw_node['alignment'] = 'center'
        
        # === 5ë‹¨ê³„: ìì‹ ë…¸ë“œ ì¬ê·€ ì²˜ë¦¬ ===
        raw_children = raw_node.get('children', [])
        simplified_children = simplified_node.get('children', [])
        
        if raw_children:
            print(f"   ğŸ‘¶ [Step 4] ìì‹ ë…¸ë“œ ì²˜ë¦¬ ì‹œì‘ ({len(raw_children)}ê°œ)...")
            
            # id ê¸°ë°˜ ë§¤ì¹­ (simplifiedì—ì„œ)
            simplified_by_id = {child.get('id'): child for child in simplified_children} if simplified_children else {}
            
            for i, raw_child in enumerate(raw_children):
                child_id = raw_child.get('id')
                
                # ìë™ ìƒì„±ëœ Groupì¸ ê²½ìš°
                if raw_child.get('_auto_generated'):
                    print(f"      ğŸ†• ìë™ ìƒì„±ëœ Group ì²˜ë¦¬: {child_id}")
                    # ìë™ ìƒì„±ëœ Groupì€ ìì²´ì ìœ¼ë¡œ simplified_nodeë¥¼ ìƒì„±
                    auto_simplified = {
                        'id': child_id,
                        'type': raw_child.get('type', 'Group'),
                        'role': raw_child.get('role', ''),
                        'children': raw_child.get('children', [])  # ìì‹ì€ ì´ë¯¸ raw_childì— ìˆìŒ
                    }
                    simplified_child = auto_simplified
                else:
                    simplified_child = simplified_by_id.get(child_id)
                
                if not simplified_child:
                    print(f"      âš ï¸ ë§¤ì¹­ë˜ì§€ ì•Šì€ ìì‹: {child_id}")
                    # ë§¤ì¹­ë˜ì§€ ì•Šì•„ë„ raw_child ìì²´ë¥¼ simplifiedë¡œ ì‚¬ìš©í•˜ì—¬ ê³„ì† ì²˜ë¦¬
                    simplified_child = raw_child
                
                # í˜•ì œ ë…¸ë“œë“¤ (ì˜¤ë¥¸ìª½ í˜•ì œë§Œ)
                child_siblings = raw_children[i+1:] if i < len(raw_children) - 1 else []
                
                print(f"      ğŸ”½ ìì‹ {i+1}/{len(raw_children)}: {child_id}")
                
                # ì¬ê·€ í˜¸ì¶œ
                self._process_node(
                    raw_child,
                    simplified_child,
                    raw_node,  # í˜„ì¬ ë…¸ë“œê°€ ë¶€ëª¨ê°€ ë¨
                    child_siblings,
                    False  # ë” ì´ìƒ ë£¨íŠ¸ê°€ ì•„ë‹˜
                )
            
            print(f"   âœ… ìì‹ ë…¸ë“œ ì²˜ë¦¬ ì™„ë£Œ")
        
        print(f"âœ… ì™„ë£Œ: {node_id}\n")
    
    def process_node_by_id(self, raw_data_path: str, simplified_path: str,
                          target_id: str) -> Dict:
        """íŠ¹ì • idì˜ ë…¸ë“œë§Œ ì²˜ë¦¬"""
        raw_data = load_json_partial(raw_data_path, target_id)
        simplified_structure = load_json_partial(simplified_path, target_id)
        return self.process(raw_data, simplified_structure, target_id)
    
    def validate_structure(self, simplified_structure: Dict) -> Dict:
        """
        Role ê²€ì¦ë§Œ ìˆ˜í–‰ (ë‹¤ë¥¸ ì†ì„± ì¶”ê°€ ì—†ì´)
        
        Args:
            simplified_structure: simplified_structure JSON
        
        Returns:
            ê²€ì¦ ë¦¬í¬íŠ¸ê°€ í¬í•¨ëœ ê²°ê³¼
        """
        result = deepcopy(simplified_structure)
        self.validation_results = []
        
        # ê²€ì¦ë§Œ ìˆ˜í–‰í•˜ëŠ” ì¬ê·€ í•¨ìˆ˜
        self._validate_node_recursive(result, None, [])
        
        # ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        report = self.role_validator.generate_validation_report(self.validation_results)
        result['_validation_report'] = report
        self._print_validation_summary(report)
        
        return result
    
    def _validate_node_recursive(self, node: Dict, parent: Optional[Dict], 
                                  siblings: List[Dict]):
        """ê²€ì¦ë§Œ ìˆ˜í–‰í•˜ëŠ” ì¬ê·€ í•¨ìˆ˜"""
        node_id = node.get('id', 'unknown')
        node_role = node.get('role', 'N/A')
        
        print(f"ğŸ” ê²€ì¦ ì¤‘: {node_id} (Role: {node_role})")
        
        children = node.get('children', [])
        
        # Role ê²€ì¦
        try:
            validation_result, was_modified = self.role_validator.validate_and_fix(
                node, parent, siblings, children
            )
            self.validation_results.append(validation_result)
            
            if validation_result.get('is_valid'):
                print(f"   âœ… ìœ íš¨ (ì‹ ë¢°ë„: {validation_result.get('confidence', 0):.0%})")
            else:
                issues_count = len(validation_result.get('issues', []))
                print(f"   âš ï¸ ë¬¸ì œ ë°œê²¬: {issues_count}ê°œ ì´ìŠˆ")
                for issue in validation_result.get('issues', [])[:3]:
                    severity_icon = {'error': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}.get(
                        issue.get('severity', 'info'), 'ğŸ”µ'
                    )
                    print(f"      {severity_icon} {issue.get('description', '')}")
        except Exception as e:
            print(f"   âš ï¸ ê²€ì¦ ì˜¤ë¥˜: {e}")
        
        # ìì‹ ë…¸ë“œ ì¬ê·€ ì²˜ë¦¬
        for i, child in enumerate(children):
            child_siblings = children[i+1:] if i < len(children) - 1 else []
            self._validate_node_recursive(child, node, child_siblings)


class ParallelLLMCoordinatorAgent:
    """
    ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „ì˜ LLM Coordinator (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
    - depthë³„ë¡œ ë…¸ë“œë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ê°™ì€ depthëŠ” ë™ì‹œ ì²˜ë¦¬
    - asyncioë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° ë³‘ë ¬ í˜¸ì¶œ
    - ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ í†µí•œ ì‹œê°ì  ë¶„ì„ ì§€ì›
    """
    
    def __init__(self, llm_client, prompt_loader: Optional[PromptLoader] = None,
                 enable_role_validation: bool = True,
                 max_concurrent: int = 10,
                 reference_image_path: Optional[str] = None):
        """
        Args:
            llm_client: ë™ê¸° LLM í´ë¼ì´ì–¸íŠ¸ (OpenAI)
            prompt_loader: í”„ë¡¬í”„íŠ¸ ë¡œë”
            enable_role_validation: Role ê²€ì¦ í™œì„±í™” ì—¬ë¶€
            max_concurrent: ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜
            reference_image_path: ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ (ë©€í‹°ëª¨ë‹¬ ë¶„ì„ìš©)
        """
        self.llm_client = llm_client
        self.prompt_loader = prompt_loader or PromptLoader()
        self.enable_role_validation = enable_role_validation
        self.max_concurrent = max_concurrent
        self.reference_image_path = reference_image_path
        
        # ì—ì´ì „íŠ¸ë“¤ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
        self.role_validator = LLMRoleValidatorAgent(
            llm_client, self.prompt_loader, reference_image_path
        )
        self.rule_analyzer = LLMRuleAnalyzerAgent(llm_client, self.prompt_loader)
        self.layout_analyzer = LLMLayoutAnalyzerAgent(llm_client, self.prompt_loader)
        self.alignment_enricher = LLMAlignmentEnricherAgent(llm_client, self.prompt_loader)
        
        self.validation_results = []
        self._semaphore = None  # asyncio.Semaphore
    
    def process(self, raw_data: Dict, simplified_structure: Dict,
                target_id: Optional[str] = None) -> Dict:
        """
        ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        """
        # raw_dataë¥¼ ë³µì‚¬í•˜ì—¬ ì‘ì—…
        result = deepcopy(raw_data)
        self.validation_results = []
        
        # asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
        try:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # Jupyter ë“±ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°
                import nest_asyncio
                nest_asyncio.apply()
        except RuntimeError:
            pass
        
        asyncio.run(self._process_parallel(result, simplified_structure))
        
        # Role ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        if self.enable_role_validation and self.validation_results:
            report = self.role_validator.generate_validation_report(self.validation_results)
            result['_validation_report'] = report
            self._print_validation_summary(report)
        
        return result
    
    def validate_only(self, raw_data: Dict, simplified_structure: Dict) -> Dict:
        """
        Role ê²€ì¦ë§Œ ë³‘ë ¬ë¡œ ìˆ˜í–‰ (resizing, layout, alignment ìŠ¤í‚µ)
        """
        result = deepcopy(raw_data)
        self.validation_results = []
        
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import nest_asyncio
                nest_asyncio.apply()
        except RuntimeError:
            pass
        
        asyncio.run(self._validate_parallel(result, simplified_structure))
        
        # Role ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        if self.validation_results:
            report = self.role_validator.generate_validation_report(self.validation_results)
            result['_validation_report'] = report
            self._print_validation_summary(report)
        
        return result
    
    async def _validate_parallel(self, raw_data: Dict, simplified_structure: Dict):
        """
        Role ê²€ì¦ë§Œ ë³‘ë ¬ ì²˜ë¦¬
        """
        self._semaphore = asyncio.Semaphore(self.max_concurrent)
        
        depth_groups = self._group_nodes_by_depth(raw_data, simplified_structure)
        
        total_nodes = sum(len(nodes) for nodes in depth_groups.values())
        print(f"\nğŸ“Š ì´ {total_nodes}ê°œ ë…¸ë“œë¥¼ {len(depth_groups)}ê°œ depthë¡œ ê²€ì¦")
        
        for depth in sorted(depth_groups.keys()):
            nodes_info = depth_groups[depth]
            print(f"\nğŸ” [Depth {depth}] {len(nodes_info)}ê°œ ë…¸ë“œ ê²€ì¦ ì¤‘...")
            
            tasks = []
            for node_info in nodes_info:
                task = self._validate_single_node_async(node_info)
                tasks.append(task)
            
            await asyncio.gather(*tasks)
            print(f"   âœ… [Depth {depth}] ì™„ë£Œ")
    
    async def _validate_single_node_async(self, node_info: Dict):
        """
        ë‹¨ì¼ ë…¸ë“œ Role ê²€ì¦ë§Œ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (resizing/layout/alignment ì—†ìŒ!)
        """
        async with self._semaphore:
            raw_node = node_info['raw_node']
            parent = node_info['parent']
            siblings = node_info['siblings']
            
            node_id = raw_node.get('id', 'unknown')
            
            loop = asyncio.get_event_loop()
            
            try:
                # Role Validationë§Œ ìˆ˜í–‰!
                children = raw_node.get('children', [])
                validation_result = await loop.run_in_executor(
                    None,
                    lambda: self._run_validation(raw_node, parent, siblings, children)
                )
                if validation_result:
                    self.validation_results.append(validation_result)
                
                print(f"      âœ“ {node_id}")
                
            except Exception as e:
                print(f"      âœ— {node_id}: {e}")
    
    async def _process_parallel(self, raw_data: Dict, simplified_structure: Dict):
        """
        depthë³„ ë³‘ë ¬ ì²˜ë¦¬ ë©”ì¸ ë¡œì§
        """
        self._semaphore = asyncio.Semaphore(self.max_concurrent)
        
        # 1. ë…¸ë“œë¥¼ depthë³„ë¡œ ê·¸ë£¹í™”
        depth_groups = self._group_nodes_by_depth(raw_data, simplified_structure)
        
        total_nodes = sum(len(nodes) for nodes in depth_groups.values())
        print(f"\nğŸ“Š ì´ {total_nodes}ê°œ ë…¸ë“œë¥¼ {len(depth_groups)}ê°œ depthë¡œ ë³‘ë ¬ ì²˜ë¦¬")
        
        # 2. depth ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ (ê° depth ë‚´ì—ì„œëŠ” ë³‘ë ¬)
        for depth in sorted(depth_groups.keys()):
            nodes_info = depth_groups[depth]
            print(f"\nğŸ”„ [Depth {depth}] {len(nodes_info)}ê°œ ë…¸ë“œ ë™ì‹œ ì²˜ë¦¬ ì¤‘...")
            
            # ê°™ì€ depthì˜ ë…¸ë“œë“¤ì„ ë™ì‹œì— ì²˜ë¦¬
            tasks = []
            for node_info in nodes_info:
                task = self._process_single_node_async(node_info)
                tasks.append(task)
            
            # ëª¨ë“  íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰
            await asyncio.gather(*tasks)
            
            print(f"   âœ… [Depth {depth}] ì™„ë£Œ")
    
    def _group_nodes_by_depth(self, raw_data: Dict, simplified_data: Dict) -> Dict[int, List[Dict]]:
        """
        íŠ¸ë¦¬ì˜ ëª¨ë“  ë…¸ë“œë¥¼ depthë³„ë¡œ ê·¸ë£¹í™”
        
        Returns:
            {depth: [(raw_node, simplified_node, parent, siblings), ...]}
        """
        depth_groups = {}
        
        def traverse(raw_node: Dict, simplified_node: Dict, 
                    parent: Optional[Dict], siblings: List[Dict], depth: int):
            """DFSë¡œ íŠ¸ë¦¬ ìˆœíšŒí•˜ë©° ë…¸ë“œ ì •ë³´ ìˆ˜ì§‘"""
            
            if depth not in depth_groups:
                depth_groups[depth] = []
            
            # ë…¸ë“œ ì •ë³´ ì €ì¥
            depth_groups[depth].append({
                'raw_node': raw_node,
                'simplified_node': simplified_node,
                'parent': parent,
                'siblings': siblings,
                'depth': depth
            })
            
            # ìì‹ ë…¸ë“œ ì²˜ë¦¬
            raw_children = raw_node.get('children', [])
            simplified_children = simplified_node.get('children', []) if simplified_node else []
            simplified_by_id = {c.get('id'): c for c in simplified_children}
            
            for i, raw_child in enumerate(raw_children):
                child_id = raw_child.get('id')
                simplified_child = simplified_by_id.get(child_id, raw_child)
                child_siblings = raw_children[i+1:] if i < len(raw_children) - 1 else []
                
                traverse(raw_child, simplified_child, raw_node, child_siblings, depth + 1)
        
        traverse(raw_data, simplified_data, None, [], 0)
        return depth_groups
    
    async def _process_single_node_async(self, node_info: Dict):
        """
        ë‹¨ì¼ ë…¸ë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
        """
        async with self._semaphore:  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
            raw_node = node_info['raw_node']
            parent = node_info['parent']
            siblings = node_info['siblings']
            
            node_id = raw_node.get('id', 'unknown')
            
            # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•´ ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            
            try:
                # Step 0: Role Validation (ë³‘ë ¬)
                if self.enable_role_validation:
                    children = raw_node.get('children', [])
                    validation_result = await loop.run_in_executor(
                        None,
                        lambda: self._run_validation(raw_node, parent, siblings, children)
                    )
                    if validation_result:
                        self.validation_results.append(validation_result)
                
                # Step 1: Resizing (ë³‘ë ¬)
                await loop.run_in_executor(
                    None,
                    lambda: self._run_resizing(raw_node, parent, siblings)
                )
                
                # Step 2: Layout (ë³‘ë ¬)
                await loop.run_in_executor(
                    None,
                    lambda: self._run_layout(raw_node, parent)
                )
                
                # Step 3: Alignment (ë³‘ë ¬)
                await loop.run_in_executor(
                    None,
                    lambda: self._run_alignment(raw_node, parent)
                )
                
                print(f"      âœ“ {node_id}")
                
            except Exception as e:
                print(f"      âœ— {node_id}: {e}")
    
    def _run_validation(self, node: Dict, parent: Optional[Dict], 
                       siblings: List[Dict], children: List[Dict]) -> Optional[Dict]:
        """Role Validation ì‹¤í–‰"""
        try:
            result, _ = self.role_validator.validate_and_fix(node, parent, siblings, children)
            return result
        except Exception as e:
            print(f"      âš ï¸ Validation ì˜¤ë¥˜: {e}")
            return None
    
    def _run_resizing(self, node: Dict, parent: Optional[Dict], siblings: List[Dict]):
        """Resizing ì‹¤í–‰"""
        try:
            self.rule_analyzer.determine_resizing(node, parent, siblings, [], False)
        except Exception as e:
            node['resizing'] = 'fill * fill'
    
    def _run_layout(self, node: Dict, parent: Optional[Dict]):
        """Layout ì‹¤í–‰"""
        try:
            self.layout_analyzer.analyze_and_enrich(node, parent)
        except Exception as e:
            if 'direction' not in node:
                node['direction'] = 'vertical'
    
    def _run_alignment(self, node: Dict, parent: Optional[Dict]):
        """Alignment ì‹¤í–‰"""
        try:
            self.alignment_enricher.enrich_alignments(node, parent)
        except Exception as e:
            if 'alignment' not in node:
                node['alignment'] = 'center'
    
    def _print_validation_summary(self, report: Dict):
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        summary = report.get('summary', {})
        print("\n" + "=" * 60)
        print("ğŸ“Š Role ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"   ì´ ë…¸ë“œ ìˆ˜: {summary.get('total_nodes', 0)}")
        print(f"   âœ… ìœ íš¨í•œ ë…¸ë“œ: {summary.get('valid_nodes', 0)}")
        print(f"   âŒ ë¬¸ì œ ìˆëŠ” ë…¸ë“œ: {summary.get('invalid_nodes', 0)}")
        print(f"   ğŸ“ˆ ê²€ì¦ í†µê³¼ìœ¨: {summary.get('validation_rate', 0):.1%}")
        print("=" * 60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    import os
    from json_utils import save_simplified_structure
    
    # íŒŒì¼ ê²½ë¡œ
    simplified_path = 'data/simplified_structure.json'
    raw_data_path = 'data/raw_data.json'
    output_path = 'data/llm_enriched_output.json'
    
    # raw_data.json ì¡´ì¬ í™•ì¸
    if not os.path.exists(raw_data_path):
        print(f"âŒ raw_data.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {raw_data_path}")
        return
    
    # simplified_structure.json ì—†ìœ¼ë©´ ìë™ ìƒì„±
    if not os.path.exists(simplified_path):
        print(f"ğŸ“ simplified_structure.jsonì´ ì—†ìŠµë‹ˆë‹¤. ìë™ ìƒì„± ì¤‘...")
        try:
            save_simplified_structure(raw_data_path, simplified_path)
        except Exception as e:
            print(f"âŒ simplified_structure ìƒì„± ì‹¤íŒ¨: {e}")
            return
    
    # LLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    llm_client = None
    try:
        from openai import OpenAI
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            llm_client = OpenAI(api_key=api_key)
            print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n")
        else:
            print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   export OPENAI_API_KEY='your-api-key' ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
            return
    except ImportError:
        print("âŒ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   pip install openai ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return
    
    # ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ
    use_partial = '--partial' in sys.argv
    enable_validation = '--no-validation' not in sys.argv
    validation_only = '--validate-only' in sys.argv
    use_parallel = '--parallel' in sys.argv
    target_id = None
    max_concurrent = 10  # ê¸°ë³¸ ë™ì‹œ ìš”ì²­ ìˆ˜
    reference_image_path = None  # ë©€í‹°ëª¨ë‹¬ ì°¸ì¡° ì´ë¯¸ì§€
    
    if '--node' in sys.argv:
        idx = sys.argv.index('--node')
        if idx + 1 < len(sys.argv):
            target_id = sys.argv[idx + 1]
            use_partial = True
    
    if '--concurrent' in sys.argv:
        idx = sys.argv.index('--concurrent')
        if idx + 1 < len(sys.argv):
            try:
                max_concurrent = int(sys.argv[idx + 1])
            except ValueError:
                pass
    
    # ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ
    if '--image' in sys.argv:
        idx = sys.argv.index('--image')
        if idx + 1 < len(sys.argv):
            reference_image_path = sys.argv[idx + 1]
            if not os.path.exists(reference_image_path):
                print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}")
                reference_image_path = None
    
    print("=" * 60)
    print("LLM ì „ìš© ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)")
    print("=" * 60)
    print()
    print(f"ğŸ“‹ ì„¤ì •:")
    print(f"   - Role ê²€ì¦: {'âœ… í™œì„±í™”' if enable_validation else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"   - Role ê²€ì¦+ìˆ˜ì •ë§Œ: {'âœ… ì˜ˆ (resizing/layout/alignment ìŠ¤í‚µ)' if validation_only else 'âŒ ì•„ë‹ˆì˜¤ (ì „ì²´ ì²˜ë¦¬)'}")
    print(f"   - ë³‘ë ¬ ì²˜ë¦¬: {'âœ… í™œì„±í™” (ë™ì‹œ ' + str(max_concurrent) + 'ê°œ)' if use_parallel else 'âŒ ë¹„í™œì„±í™” (ìˆœì°¨)'}")
    print(f"   - ì°¸ì¡° ì´ë¯¸ì§€: {'ğŸ“· ' + reference_image_path if reference_image_path else 'âŒ ì—†ìŒ (JSONë§Œ ë¶„ì„)'}")
    print()
    
    if use_partial and target_id:
        print(f"ğŸ” íŠ¹ì • ë…¸ë“œë§Œ ì²˜ë¦¬: {target_id}\n")
        coordinator = LLMCoordinatorAgent(
            llm_client, 
            use_partial_loading=True,
            enable_role_validation=enable_validation,
            reference_image_path=reference_image_path
        )
        result = coordinator.process_node_by_id(
            raw_data_path, simplified_path, target_id
        )
    else:
        print("ğŸ“¦ ì „ì²´ íŒŒì¼ ì²˜ë¦¬ ì¤‘...\n")
        with open(simplified_path, 'r', encoding='utf-8') as f:
            simplified_structure = json.load(f)
        
        with open(raw_data_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        import time
        start_time = time.time()
        
        if use_parallel:
            # ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ
            print("âš¡ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤...\n")
            coordinator = ParallelLLMCoordinatorAgent(
                llm_client,
                enable_role_validation=enable_validation,
                max_concurrent=max_concurrent,
                reference_image_path=reference_image_path
            )
            
            if validation_only:
                # Role ê²€ì¦+ìˆ˜ì •ë§Œ (ë³‘ë ¬)
                print("ğŸ” Role ê²€ì¦+ìˆ˜ì •ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë³‘ë ¬)...\n")
                result = coordinator.validate_only(raw_data, simplified_structure)
            else:
                result = coordinator.process(raw_data, simplified_structure, target_id)
        else:
            # ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ
            coordinator = LLMCoordinatorAgent(
                llm_client, 
                use_partial_loading=use_partial,
                enable_role_validation=enable_validation,
                reference_image_path=reference_image_path
            )
            
            if validation_only:
                # Role ê²€ì¦+ìˆ˜ì •ë§Œ
                print("ğŸ” Role ê²€ì¦+ìˆ˜ì •ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤...\n")
                result = coordinator.validate_structure(simplified_structure)
            else:
                result = coordinator.process(raw_data, simplified_structure, target_id)
        
        elapsed_time = time.time() - start_time
        print(f"\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
    
    # ê²°ê³¼ ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 60)
    print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("=" * 60)


if __name__ == '__main__':
    main()
