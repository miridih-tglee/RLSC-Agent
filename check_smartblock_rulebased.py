"""
ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨ - ë£°ë² ì´ìŠ¤ ë²„ì „
content_signature.jsonì„ ë¶„ì„í•˜ì—¬ LLM ì—†ì´ ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨

í•µì‹¬ ë¡œì§:
1. ì»¨í…Œì´ë„ˆ(Grid, HStack, VStack)ì˜ childrenì´ 2ê°œ ì´ìƒì¸ì§€ í™•ì¸
2. childrenì˜ êµ¬ì¡°ì  ì‹œê·¸ë‹ˆì²˜ê°€ ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œì§€ ë¹„êµ
3. ë™ì¼/ìœ ì‚¬í•œ êµ¬ì¡°ê°€ ë°˜ë³µë˜ë©´ ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©

v2: ìœ ì‚¬ë„ ê¸°ë°˜ ë¹„êµ ì¶”ê°€ (ì™„ì „ ì¼ì¹˜ + ìœ ì‚¬ êµ¬ì¡° ëª¨ë‘ ì¸ì‹)
v3: DB ì—°ë™ - valid_container_ids.json ì…ë ¥ ì§€ì›
"""

import json
import hashlib
import sys
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import Counter
from itertools import combinations
import argparse

# DB ì„¤ì • (process_design_object.pyì™€ ë™ì¼)
DB_CONFIG = {
    "host": "127.0.0.1",
    "port": 54322,
    "user": "postgres",
    "password": "postgres",
    "dbname": "postgres"
}


def get_db_connection():
    """DB ì—°ê²° ìƒì„±"""
    try:
        import psycopg2
        import psycopg2.extras
        return psycopg2.connect(**DB_CONFIG)
    except ImportError:
        print("âŒ psycopg2ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install psycopg2-binary")
        sys.exit(1)


def fetch_content_signature_from_db(object_id: int) -> Optional[List[Dict]]:
    """DBì—ì„œ content_signature ì¡°íšŒ"""
    import psycopg2.extras
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
            cur.execute(
                "SELECT content_signature FROM design_objects WHERE id = %s",
                (object_id,)
            )
            result = cur.fetchone()
            if result and result.get("content_signature"):
                return result["content_signature"]
            return None
    finally:
        conn.close()


def fetch_content_signatures_batch(object_ids: List[int], batch_size: int = 500) -> Dict[int, List[Dict]]:
    """DBì—ì„œ ì—¬ëŸ¬ content_signature ì¼ê´„ ì¡°íšŒ"""
    import psycopg2.extras
    results = {}
    conn = get_db_connection()

    try:
        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
            for i in range(0, len(object_ids), batch_size):
                batch = object_ids[i:i + batch_size]
                cur.execute(
                    "SELECT id, content_signature FROM design_objects WHERE id = ANY(%s)",
                    (batch,)
                )
                for row in cur.fetchall():
                    if row.get("content_signature"):
                        results[row["id"]] = row["content_signature"]
    finally:
        conn.close()

    return results


@dataclass
class SmartBlockResult:
    """ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨ ê²°ê³¼"""
    is_eligible: bool
    score: int  # 1-10
    repeatable_count: int
    repeatable_type: str
    container_type: str
    pattern_description: str
    details: Dict[str, Any]


def get_structure_signature(node: Dict[str, Any], depth: int = 0, max_depth: int = 3) -> str:
    """
    ë…¸ë“œì˜ êµ¬ì¡°ì  ì‹œê·¸ë‹ˆì²˜ë¥¼ ìƒì„±
    typeê³¼ roleë§Œ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡° ë¹„êµ (textCapacity ë“± ì„¸ë¶€ ê°’ì€ ë¬´ì‹œ)
    """
    if depth > max_depth:
        return "..."

    node_type = node.get("type", "Unknown")
    node_role = node.get("role", "null")

    children = node.get("children", [])
    if children:
        child_sigs = [get_structure_signature(c, depth + 1, max_depth) for c in children]
        children_str = ",".join(child_sigs)
        return f"{node_role}:{node_type}[{children_str}]"
    else:
        return f"{node_role}:{node_type}"


def get_structure_hash(node: Dict[str, Any], max_depth: int = 3) -> str:
    """êµ¬ì¡° ì‹œê·¸ë‹ˆì²˜ì˜ í•´ì‹œê°’ ë°˜í™˜ (ë¹„êµìš©)"""
    sig = get_structure_signature(node, max_depth=max_depth)
    return hashlib.md5(sig.encode()).hexdigest()[:8]


# ============================================================
# ìœ ì‚¬ë„ ê¸°ë°˜ ë¹„êµ (v2)
# ============================================================

def get_skeleton_signature(node: Dict[str, Any], depth: int = 0, max_depth: int = 2) -> str:
    """
    ìŠ¤ì¼ˆë ˆí†¤ ì‹œê·¸ë‹ˆì²˜: children ê°œìˆ˜ ë¬´ì‹œ, íƒ€ì…ë§Œ ë¹„êµ
    ì˜ˆ: VStack[Title:Text, Description:Text, Description:Text]
        â†’ VStack[Title:Text, Description:Text]  (ì¤‘ë³µ ì œê±°)
    """
    if depth > max_depth:
        return "..."

    node_type = node.get("type", "Unknown")
    node_role = node.get("role", "null")

    children = node.get("children", [])
    if children:
        # ê° childì˜ ìŠ¤ì¼ˆë ˆí†¤ ì¶”ì¶œ í›„ ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
        child_sigs = []
        seen = set()
        for c in children:
            sig = get_skeleton_signature(c, depth + 1, max_depth)
            if sig not in seen:
                child_sigs.append(sig)
                seen.add(sig)
        children_str = ",".join(child_sigs)
        return f"{node_role}:{node_type}[{children_str}]"
    else:
        return f"{node_role}:{node_type}"


def count_leaf_nodes(node: Dict[str, Any]) -> int:
    """
    ë…¸ë“œ ë‚´ì˜ leaf ë…¸ë“œ(Text, SVG, Image, Frame) ê°œìˆ˜ë¥¼ ì…ˆ
    ì‘ì€ ë¼ë²¨ ê·¸ë£¹(ì˜ˆ: SVG + Text = 2ê°œ)ì„ ê±¸ëŸ¬ë‚´ê¸° ìœ„í•œ í•„í„°ìš©
    """
    leaf_types = {"Text", "SVG", "Image", "Frame"}
    node_type = node.get("type", "")
    children = node.get("children", [])

    if node_type in leaf_types:
        return 1

    count = 0
    for child in children:
        count += count_leaf_nodes(child)
    return count


def get_feature_set(node: Dict[str, Any], depth: int = 0, max_depth: int = 2) -> Set[str]:
    """
    ë…¸ë“œì˜ íŠ¹ì§• ì§‘í•© ì¶”ì¶œ: (depth, role, type) íŠœí”Œë“¤ì˜ ì§‘í•©
    êµ¬ì¡°ê°€ ì•½ê°„ ë‹¬ë¼ë„ í•µì‹¬ ìš”ì†Œê°€ ê°™ìœ¼ë©´ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨
    """
    features = set()

    if depth > max_depth:
        return features

    node_type = node.get("type", "Unknown")
    node_role = node.get("role") or "null"

    # í˜„ì¬ ë…¸ë“œì˜ íŠ¹ì§• ì¶”ê°€
    features.add(f"d{depth}:{node_role}:{node_type}")

    # ìì‹ ë…¸ë“œë“¤ì˜ íŠ¹ì§•ë„ ì¶”ê°€
    for child in node.get("children", []):
        features.update(get_feature_set(child, depth + 1, max_depth))

    return features


def calculate_similarity(node1: Dict[str, Any], node2: Dict[str, Any]) -> float:
    """
    ë‘ ë…¸ë“œ ê°„ì˜ êµ¬ì¡°ì  ìœ ì‚¬ë„ ê³„ì‚° (Jaccard similarity)
    0.0 ~ 1.0 ë°˜í™˜
    """
    features1 = get_feature_set(node1)
    features2 = get_feature_set(node2)

    if not features1 and not features2:
        return 1.0
    if not features1 or not features2:
        return 0.0

    intersection = features1 & features2
    union = features1 | features2

    return len(intersection) / len(union)


def find_similar_groups(children: List[Dict[str, Any]], threshold: float = 0.7) -> List[List[int]]:
    """
    ìœ ì‚¬í•œ childrenë¼ë¦¬ ê·¸ë£¹í™”
    threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.7 = 70% ì´ìƒ ìœ ì‚¬í•˜ë©´ ê°™ì€ ê·¸ë£¹)

    Returns: ê·¸ë£¹ë³„ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [[0, 1, 2], [3, 4]])
    """
    n = len(children)
    if n < 2:
        return []

    # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    similarity_matrix = {}
    for i, j in combinations(range(n), 2):
        sim = calculate_similarity(children[i], children[j])
        similarity_matrix[(i, j)] = sim
        similarity_matrix[(j, i)] = sim

    # Union-Findë¡œ ê·¸ë£¹í™”
    parent = list(range(n))

    def find(x):
        if parent[x] != x:
            parent[x] = find(parent[x])
        return parent[x]

    def union(x, y):
        px, py = find(x), find(y)
        if px != py:
            parent[px] = py

    # ìœ ì‚¬ë„ê°€ threshold ì´ìƒì¸ ìŒ í•©ì¹˜ê¸°
    for (i, j), sim in similarity_matrix.items():
        if i < j and sim >= threshold:
            union(i, j)

    # ê·¸ë£¹ë³„ë¡œ ì •ë¦¬
    groups = {}
    for i in range(n):
        root = find(i)
        if root not in groups:
            groups[root] = []
        groups[root].append(i)

    # 2ê°œ ì´ìƒì¸ ê·¸ë£¹ë§Œ ë°˜í™˜
    return [indices for indices in groups.values() if len(indices) >= 2]


def find_repeating_containers(node: Dict[str, Any], path: str = "root", use_similarity: bool = True, min_leaf_count: int = 3) -> List[Dict[str, Any]]:
    """
    ë°˜ë³µë˜ëŠ” childrenì„ ê°€ì§„ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ìŒ

    Args:
        use_similarity: Trueë©´ ìœ ì‚¬ë„ ê¸°ë°˜ ë¹„êµë„ ì‚¬ìš© (ì•½ê°„ ë‹¤ë¥¸ êµ¬ì¡°ë„ ì¸ì‹)
        min_leaf_count: ìµœì†Œ leaf ë…¸ë“œ ìˆ˜ (ê¸°ë³¸ 3). ì‘ì€ ë¼ë²¨ ê·¸ë£¹ í•„í„°ë§

    í•µì‹¬: children ì¤‘ **ì»¨í…Œì´ë„ˆ íƒ€ì…**(VStack, HStack, ZStack, Group, Grid)ë§Œ ë°˜ë³µ ì²´í¬
          leaf ë…¸ë“œ(Text, SVG, Image)ì˜ ë°˜ë³µì€ ìŠ¤ë§ˆíŠ¸ë¸”ë¡ì— ì˜ë¯¸ ì—†ìŒ
          â­ ì¶”ê°€: leaf ë…¸ë“œê°€ min_leaf_count ë¯¸ë§Œì¸ ì‘ì€ ì»¨í…Œì´ë„ˆëŠ” ë¬´ì‹œ
    """
    results = []

    node_type = node.get("type", "")
    children = node.get("children", [])

    # ì»¨í…Œì´ë„ˆ íƒ€ì… ì •ì˜
    container_types = {"Grid", "HStack", "VStack", "ZStack", "Group"}

    if node_type in container_types and len(children) >= 2:
        # â­ í•µì‹¬: ì»¨í…Œì´ë„ˆ íƒ€ì…ì¸ childrenë§Œ í•„í„°ë§
        # â­ ì¶”ê°€: leaf ë…¸ë“œê°€ min_leaf_count ì´ìƒì¸ ì»¨í…Œì´ë„ˆë§Œ í¬í•¨
        container_children = []
        container_indices = []
        for i, child in enumerate(children):
            child_type = child.get("type", "")
            if child_type in container_types:
                leaf_count = count_leaf_nodes(child)
                if leaf_count >= min_leaf_count:
                    container_children.append(child)
                    container_indices.append(i)

        # ì»¨í…Œì´ë„ˆ childrenì´ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ë°˜ë³µ ì²´í¬
        if len(container_children) >= 2:
            # ê° ì»¨í…Œì´ë„ˆ childì˜ êµ¬ì¡° ì‹œê·¸ë‹ˆì²˜ ê³„ì‚°
            child_signatures = []
            for idx, child in zip(container_indices, container_children):
                sig = get_structure_signature(child)
                sig_hash = get_structure_hash(child)
                skeleton = get_skeleton_signature(child)
                skeleton_hash = hashlib.md5(skeleton.encode()).hexdigest()[:8]
                child_signatures.append({
                    "index": idx,
                    "signature": sig,
                    "hash": sig_hash,
                    "skeleton": skeleton,
                    "skeleton_hash": skeleton_hash,
                    "type": child.get("type", "Unknown"),
                    "role": child.get("role", "null")
                })

            best_result = None

            # ë°©ë²• 1: ì™„ì „ ì¼ì¹˜ (ê¸°ì¡´ ë°©ì‹)
            hash_counter = Counter(cs["hash"] for cs in child_signatures)
            most_common_hash, exact_count = hash_counter.most_common(1)[0]

            if exact_count >= 2:
                repeating_children = [cs for cs in child_signatures if cs["hash"] == most_common_hash]
                best_result = {
                    "path": path,
                    "container_type": node_type,
                    "container_role": node.get("role", "null"),
                    "total_children": len(container_children),
                    "repeating_count": exact_count,
                    "repeating_ratio": exact_count / len(container_children),
                    "repeating_children": repeating_children,
                    "sample_signature": repeating_children[0]["signature"] if repeating_children else "",
                    "child_type": repeating_children[0]["type"] if repeating_children else "Unknown",
                    "child_role": repeating_children[0]["role"] if repeating_children else "null",
                    "match_type": "exact",  # ì™„ì „ ì¼ì¹˜
                    "similarity_score": 1.0,
                }

            # ë°©ë²• 2: ìŠ¤ì¼ˆë ˆí†¤ ì¼ì¹˜ (ì¤‘ë³µ ìš”ì†Œ ë¬´ì‹œ)
            skeleton_counter = Counter(cs["skeleton_hash"] for cs in child_signatures)
            most_common_skeleton, skeleton_count = skeleton_counter.most_common(1)[0]

            if skeleton_count > exact_count and skeleton_count >= 2:
                repeating_children = [cs for cs in child_signatures if cs["skeleton_hash"] == most_common_skeleton]
                best_result = {
                    "path": path,
                    "container_type": node_type,
                    "container_role": node.get("role", "null"),
                    "total_children": len(container_children),
                    "repeating_count": skeleton_count,
                    "repeating_ratio": skeleton_count / len(container_children),
                    "repeating_children": repeating_children,
                    "sample_signature": repeating_children[0]["signature"] if repeating_children else "",
                    "child_type": repeating_children[0]["type"] if repeating_children else "Unknown",
                    "child_role": repeating_children[0]["role"] if repeating_children else "null",
                    "match_type": "skeleton",  # ìŠ¤ì¼ˆë ˆí†¤ ì¼ì¹˜
                    "similarity_score": 0.9,
                }

            # ë°©ë²• 3: ìœ ì‚¬ë„ ê¸°ë°˜ ê·¸ë£¹í™” (threshold 70%)
            if use_similarity:
                # â­ ì»¨í…Œì´ë„ˆ childrenë§Œ ì‚¬ìš©
                similar_groups = find_similar_groups(container_children, threshold=0.7)
                if similar_groups:
                    largest_group = max(similar_groups, key=len)
                    similarity_count = len(largest_group)

                    # ê·¸ë£¹ ë‚´ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
                    if similarity_count >= 2:
                        sims = []
                        for i, j in combinations(largest_group, 2):
                            sims.append(calculate_similarity(container_children[i], container_children[j]))
                        avg_similarity = sum(sims) / len(sims) if sims else 0

                        # ìœ ì‚¬ë„ ê¸°ë°˜ ê²°ê³¼ê°€ ë” ë‚˜ì€ ê²½ìš°ì—ë§Œ ì‚¬ìš©
                        if best_result is None or similarity_count > best_result["repeating_count"]:
                            repeating_children = [child_signatures[i] for i in largest_group]
                            best_result = {
                                "path": path,
                                "container_type": node_type,
                                "container_role": node.get("role", "null"),
                                "total_children": len(container_children),
                                "repeating_count": similarity_count,
                                "repeating_ratio": similarity_count / len(container_children),
                                "repeating_children": repeating_children,
                                "sample_signature": repeating_children[0]["signature"] if repeating_children else "",
                                "child_type": repeating_children[0]["type"] if repeating_children else "Unknown",
                                "child_role": repeating_children[0]["role"] if repeating_children else "null",
                                "match_type": "similar",  # ìœ ì‚¬ë„ ê¸°ë°˜
                                "similarity_score": avg_similarity,
                            }

            if best_result:
                results.append(best_result)

    # ì¬ê·€ì ìœ¼ë¡œ children íƒìƒ‰
    for i, child in enumerate(children):
        child_path = f"{path}.{node_type}[{i}]"
        results.extend(find_repeating_containers(child, child_path, use_similarity, min_leaf_count))

    return results


def classify_pattern(container: Dict[str, Any]) -> str:
    """ë°˜ë³µ íŒ¨í„´ ë¶„ë¥˜"""
    child_sig = container.get("sample_signature", "")
    child_type = container.get("child_type", "")
    child_role = container.get("child_role", "")
    container_type = container.get("container_type", "")

    # íŒ¨í„´ ë¶„ë¥˜ ê·œì¹™
    if "Image" in child_sig or "Frame" in child_sig:
        if "Title" in child_sig and ("Description" in child_sig or "Subtitle" in child_sig):
            return "íŒ€ì›/í”„ë¡œí•„ ì¹´ë“œ"
        elif "Title" in child_sig:
            return "ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ì¹´ë“œ"
        else:
            return "ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ"

    if "SVG" in child_sig:
        if "Title" in child_sig and "Description" in child_sig:
            return "ì•„ì´ì½˜+í…ìŠ¤íŠ¸ ì¹´ë“œ"
        elif "Title" in child_sig:
            return "ì•„ì´ì½˜+ì œëª© ë¦¬ìŠ¤íŠ¸"
        else:
            return "ì•„ì´ì½˜/ì¥ì‹ ê·¸ë¦¬ë“œ"

    if child_type in {"VStack", "HStack"}:
        if "Title" in child_sig and "Description" in child_sig:
            return "ì •ë³´ ì¹´ë“œ ê·¸ë¦¬ë“œ"
        elif "Title" in child_sig:
            return "ì œëª© ë¦¬ìŠ¤íŠ¸"
        else:
            return "ì»¨í…ì¸  ë¸”ë¡ ê·¸ë¦¬ë“œ"

    if child_type == "Text":
        return "í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸"

    return "ì¼ë°˜ ë°˜ë³µ ìš”ì†Œ"


def evaluate_smartblock_eligibility(content_signature: List[Dict[str, Any]], min_leaf_count: int = 3) -> SmartBlockResult:
    """
    content_signature.jsonì„ ë¶„ì„í•˜ì—¬ ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨

    Args:
        min_leaf_count: ìµœì†Œ leaf ë…¸ë“œ ìˆ˜ (ê¸°ë³¸ 3). ì‘ì€ ë¼ë²¨ ê·¸ë£¹ í•„í„°ë§
    """
    all_repeating = []

    # ëª¨ë“  ë£¨íŠ¸ ë…¸ë“œì—ì„œ ë°˜ë³µ íŒ¨í„´ ì°¾ê¸°
    for root_node in content_signature:
        repeating = find_repeating_containers(root_node, min_leaf_count=min_leaf_count)
        all_repeating.extend(repeating)

    if not all_repeating:
        return SmartBlockResult(
            is_eligible=False,
            score=1,
            repeatable_count=0,
            repeatable_type="ì—†ìŒ",
            container_type="ì—†ìŒ",
            pattern_description="ë°˜ë³µë˜ëŠ” ìš”ì†Œê°€ ì—†ìŒ",
            details={"repeating_containers": []}
        )

    # ê°€ì¥ ìœ ì˜ë¯¸í•œ ë°˜ë³µ íŒ¨í„´ ì„ íƒ (ë°˜ë³µ íšŸìˆ˜ * ê¹Šì´ ê°€ì¤‘ì¹˜)
    best_container = max(all_repeating, key=lambda x: (
        x["repeating_count"],  # ë°˜ë³µ íšŸìˆ˜ ìš°ì„ 
        x["repeating_ratio"],  # ë¹„ìœ¨
        -len(x["path"].split("."))  # ì–•ì€ ê¹Šì´ ì„ í˜¸
    ))

    repeating_count = best_container["repeating_count"]
    repeating_ratio = best_container["repeating_ratio"]
    container_type = best_container["container_type"]
    pattern_type = classify_pattern(best_container)

    # ì ìˆ˜ ê³„ì‚°
    score = 1

    # ë°˜ë³µ íšŸìˆ˜ ê¸°ë°˜ ì ìˆ˜ (2ê°œ: +2, 3ê°œ: +3, 4ê°œ+: +4)
    if repeating_count >= 4:
        score += 4
    elif repeating_count >= 3:
        score += 3
    else:
        score += 2

    # ë°˜ë³µ ë¹„ìœ¨ ê¸°ë°˜ ì ìˆ˜ (100%: +3, 80%+: +2, 50%+: +1)
    if repeating_ratio >= 1.0:
        score += 3
    elif repeating_ratio >= 0.8:
        score += 2
    elif repeating_ratio >= 0.5:
        score += 1

    # Grid ì»¨í…Œì´ë„ˆ ë³´ë„ˆìŠ¤ (+1)
    if container_type == "Grid":
        score += 1

    # ì˜ë¯¸ìˆëŠ” íŒ¨í„´ ë³´ë„ˆìŠ¤ (+1)
    meaningful_patterns = {"íŒ€ì›/í”„ë¡œí•„ ì¹´ë“œ", "ì•„ì´ì½˜+í…ìŠ¤íŠ¸ ì¹´ë“œ", "ì •ë³´ ì¹´ë“œ ê·¸ë¦¬ë“œ", "ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ì¹´ë“œ"}
    if pattern_type in meaningful_patterns:
        score += 1

    score = min(10, score)  # ìµœëŒ€ 10ì 

    is_eligible = score >= 5 and repeating_count >= 2

    return SmartBlockResult(
        is_eligible=is_eligible,
        score=score,
        repeatable_count=repeating_count,
        repeatable_type=pattern_type,
        container_type=container_type,
        pattern_description=f"{container_type} ì•ˆì— {repeating_count}ê°œì˜ ë™ì¼í•œ {pattern_type} ë°˜ë³µ",
        details={
            "repeating_containers": all_repeating,
            "best_container": best_container,
            "total_patterns_found": len(all_repeating)
        }
    )


def analyze_folder(folder_path: Path, min_leaf_count: int = 3) -> Optional[Dict[str, Any]]:
    """ë‹¨ì¼ í´ë” ë¶„ì„"""
    content_sig_path = folder_path / "content_signature.json"

    if not content_sig_path.exists():
        return None

    try:
        with open(content_sig_path, "r", encoding="utf-8") as f:
            content_signature = json.load(f)

        result = evaluate_smartblock_eligibility(content_signature, min_leaf_count=min_leaf_count)

        return {
            "folder": folder_path.name,
            "is_eligible": result.is_eligible,
            "score": result.score,
            "repeatable_count": result.repeatable_count,
            "repeatable_type": result.repeatable_type,
            "container_type": result.container_type,
            "pattern_description": result.pattern_description,
            "total_patterns_found": result.details.get("total_patterns_found", 0),
            "match_type": result.details.get("best_container", {}).get("match_type", "unknown"),
            "similarity_score": result.details.get("best_container", {}).get("similarity_score", 0),
        }
    except Exception as e:
        return {
            "folder": folder_path.name,
            "error": str(e)
        }


def analyze_from_db(object_id: int, content_signature: List[Dict], min_leaf_count: int = 3) -> Optional[Dict[str, Any]]:
    """DBì—ì„œ ê°€ì ¸ì˜¨ content_signature ë¶„ì„"""
    try:
        result = evaluate_smartblock_eligibility(content_signature, min_leaf_count=min_leaf_count)

        return {
            "folder": str(object_id),
            "is_eligible": result.is_eligible,
            "score": result.score,
            "repeatable_count": result.repeatable_count,
            "repeatable_type": result.repeatable_type,
            "container_type": result.container_type,
            "pattern_description": result.pattern_description,
            "total_patterns_found": result.details.get("total_patterns_found", 0),
            "match_type": result.details.get("best_container", {}).get("match_type", "unknown"),
            "similarity_score": result.details.get("best_container", {}).get("similarity_score", 0),
        }
    except Exception as e:
        return {
            "folder": str(object_id),
            "error": str(e)
        }


def main():
    parser = argparse.ArgumentParser(description="ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨ (ë£°ë² ì´ìŠ¤)")
    parser.add_argument("--dir", type=str, help="ë¶„ì„í•  ë””ë ‰í† ë¦¬ (í´ë” ê¸°ë°˜)")
    parser.add_argument("--json", type=str, help="ID JSON íŒŒì¼ (DB ê¸°ë°˜) - valid_container_ids.json í˜•ì‹")
    parser.add_argument("--folder", type=str, help="íŠ¹ì • í´ë”ë§Œ ë¶„ì„")
    parser.add_argument("--limit", type=int, help="ë¶„ì„í•  ê°œìˆ˜ ì œí•œ")
    parser.add_argument("--output", type=str, help="ì „ì²´ ê²°ê³¼ JSON ì €ì¥ íŒŒì¼")
    parser.add_argument("--output-dir", type=str, default="./data", help="CSV ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--verbose", action="store_true", help="ìƒì„¸ ì¶œë ¥")
    parser.add_argument("--save-csv", action="store_true", help="sm_valid.csv, sm_invalid.csv ì €ì¥")
    parser.add_argument("--min-leaf", type=int, default=3, help="ìµœì†Œ leaf ë…¸ë“œ ìˆ˜ (ê¸°ë³¸ 3). ì‘ì€ ë¼ë²¨ ê·¸ë£¹ í•„í„°ë§")
    args = parser.parse_args()

    # ì „ì—­ ì„¤ì •ìœ¼ë¡œ min_leaf_count ì „ë‹¬
    global_min_leaf_count = args.min_leaf

    results = []

    # JSON íŒŒì¼ ê¸°ë°˜ (DBì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    if args.json:
        json_path = Path(args.json)
        if not json_path.exists():
            print(f"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
            sys.exit(1)

        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # valid_container_ids.json í˜•ì‹ ì§€ì›
        if isinstance(data, dict) and "ids" in data:
            object_ids = data["ids"]
        elif isinstance(data, list):
            object_ids = data
        else:
            print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” JSON í˜•ì‹ì…ë‹ˆë‹¤. {'ids': [...]} ë˜ëŠ” [...] í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            sys.exit(1)

        if args.limit:
            object_ids = object_ids[:args.limit]

        print("=" * 70)
        print("ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨ (ë£°ë² ì´ìŠ¤) - DB ëª¨ë“œ")
        print("=" * 70)
        print(f"ë¶„ì„ ëŒ€ìƒ: {len(object_ids)}ê°œ ID")
        print(f"ì…ë ¥ íŒŒì¼: {json_path}")
        print(f"ìµœì†Œ leaf ë…¸ë“œ ìˆ˜: {global_min_leaf_count} (ì‘ì€ ë¼ë²¨ ê·¸ë£¹ í•„í„°ë§)")
        print("=" * 70)

        # DBì—ì„œ ì¼ê´„ ì¡°íšŒ
        print(f"\nğŸ“¥ DBì—ì„œ content_signature ì¼ê´„ ì¡°íšŒ ì¤‘...")
        content_signatures = fetch_content_signatures_batch(object_ids)
        print(f"  â†’ {len(content_signatures)}ê°œ ì¡°íšŒ ì™„ë£Œ")

        # ë¶„ì„
        print(f"\nğŸ” ë¶„ì„ ì¤‘...")
        for object_id in object_ids:
            if object_id not in content_signatures:
                results.append({
                    "folder": str(object_id),
                    "error": "content_signature ì—†ìŒ"
                })
                continue

            result = analyze_from_db(object_id, content_signatures[object_id], min_leaf_count=global_min_leaf_count)
            if result:
                results.append(result)

                if "error" in result:
                    print(f"  {result['folder']}: ERROR - {result['error']}")
                else:
                    status = "âœ“ ì í•©" if result["is_eligible"] else "âœ— ë¶€ì í•©"
                    match_type = result.get("match_type", "?")
                    match_icon = {"exact": "=", "skeleton": "â‰ˆ", "similar": "~"}.get(match_type, "?")
                    print(f"  {result['folder']}: {status} | {result['score']}/10 | "
                          f"{result['repeatable_count']}ê°œ {result['repeatable_type']} [{match_icon}]")

                    if args.verbose and result.get("pattern_description"):
                        sim_score = result.get("similarity_score", 0)
                        print(f"    â†’ {result['pattern_description']} (ìœ ì‚¬ë„: {sim_score:.0%})")

    # í´ë” ê¸°ë°˜ (ê¸°ì¡´ ë°©ì‹)
    else:
        target_dir = Path(args.dir) if args.dir else Path("./negative_samples")

        if args.folder:
            folders = [target_dir / args.folder]
        else:
            folders = sorted([f for f in target_dir.iterdir() if f.is_dir()])

        if args.limit:
            folders = folders[:args.limit]

        print("=" * 70)
        print("ìŠ¤ë§ˆíŠ¸ë¸”ë¡ ì í•©ì„± íŒë‹¨ (ë£°ë² ì´ìŠ¤) - í´ë” ëª¨ë“œ")
        print("=" * 70)
        print(f"ë¶„ì„ ëŒ€ìƒ: {len(folders)}ê°œ í´ë”")
        print(f"ë””ë ‰í† ë¦¬: {target_dir}")
        print(f"ìµœì†Œ leaf ë…¸ë“œ ìˆ˜: {global_min_leaf_count} (ì‘ì€ ë¼ë²¨ ê·¸ë£¹ í•„í„°ë§)")
        print("=" * 70)

        for folder in folders:
            result = analyze_folder(folder, min_leaf_count=global_min_leaf_count)
            if result:
                results.append(result)

                if "error" in result:
                    print(f"  {result['folder']}: ERROR - {result['error']}")
                else:
                    status = "âœ“ ì í•©" if result["is_eligible"] else "âœ— ë¶€ì í•©"
                    match_type = result.get("match_type", "?")
                    match_icon = {"exact": "=", "skeleton": "â‰ˆ", "similar": "~"}.get(match_type, "?")
                    print(f"  {result['folder']}: {status} | {result['score']}/10 | "
                          f"{result['repeatable_count']}ê°œ {result['repeatable_type']} [{match_icon}]")

                    if args.verbose and result.get("pattern_description"):
                        sim_score = result.get("similarity_score", 0)
                        print(f"    â†’ {result['pattern_description']} (ìœ ì‚¬ë„: {sim_score:.0%})")

    # í†µê³„
    print("\n" + "=" * 70)
    print("ê²°ê³¼ ìš”ì•½")
    print("=" * 70)

    successful = [r for r in results if "error" not in r]
    eligible = [r for r in successful if r["is_eligible"]]

    print(f"ì´ ë¶„ì„: {len(successful)}ê°œ")
    print(f"ì í•©: {len(eligible)}ê°œ ({len(eligible)/len(successful)*100:.1f}%)")
    print(f"ë¶€ì í•©: {len(successful) - len(eligible)}ê°œ")

    if successful:
        avg_score = sum(r["score"] for r in successful) / len(successful)
        print(f"í‰ê·  ì ìˆ˜: {avg_score:.2f}/10")

        # íŒ¨í„´ í†µê³„
        pattern_counter = Counter(r["repeatable_type"] for r in successful if r["repeatable_type"] != "ì—†ìŒ")
        if pattern_counter:
            print("\nê°ì§€ëœ íŒ¨í„´:")
            for pattern, cnt in pattern_counter.most_common():
                print(f"  {pattern}: {cnt}ê°œ")

        # ë§¤ì¹­ íƒ€ì… í†µê³„
        match_type_counter = Counter(r.get("match_type", "unknown") for r in successful)
        print("\në§¤ì¹­ íƒ€ì…:")
        type_labels = {"exact": "ì™„ì „ ì¼ì¹˜ [=]", "skeleton": "ìŠ¤ì¼ˆë ˆí†¤ ì¼ì¹˜ [â‰ˆ]", "similar": "ìœ ì‚¬ë„ ê¸°ë°˜ [~]"}
        for mt, cnt in match_type_counter.most_common():
            label = type_labels.get(mt, mt)
            print(f"  {label}: {cnt}ê°œ")

    # ê²°ê³¼ ì €ì¥
    if args.output:
        output_path = Path(args.output)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nê²°ê³¼ ì €ì¥: {output_path}")

    # CSV ì €ì¥ (sm_valid.csv, sm_invalid.csv)
    if args.save_csv:
        import csv
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        valid_results = [r for r in successful if r["is_eligible"]]
        invalid_results = [r for r in successful if not r["is_eligible"]]

        csv_columns = [
            "design_object_id", "score", "repeatable_count", "repeatable_type",
            "container_type", "match_type", "similarity_score", "pattern_description"
        ]

        # sm_valid.csv
        valid_path = output_dir / "sm_valid.csv"
        with open(valid_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(csv_columns)
            for r in valid_results:
                writer.writerow([
                    r["folder"],
                    r["score"],
                    r["repeatable_count"],
                    r["repeatable_type"],
                    r["container_type"],
                    r.get("match_type", ""),
                    f"{r.get('similarity_score', 0):.2f}",
                    r.get("pattern_description", "")
                ])
        print(f"\nì í•© ê²°ê³¼ ì €ì¥: {valid_path} ({len(valid_results)}ê°œ)")

        # sm_invalid.csv
        invalid_path = output_dir / "sm_invalid.csv"
        with open(invalid_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(csv_columns)
            for r in invalid_results:
                writer.writerow([
                    r["folder"],
                    r["score"],
                    r["repeatable_count"],
                    r["repeatable_type"],
                    r["container_type"],
                    r.get("match_type", ""),
                    f"{r.get('similarity_score', 0):.2f}",
                    r.get("pattern_description", "")
                ])
        print(f"ë¶€ì í•© ê²°ê³¼ ì €ì¥: {invalid_path} ({len(invalid_results)}ê°œ)")


if __name__ == "__main__":
    main()
